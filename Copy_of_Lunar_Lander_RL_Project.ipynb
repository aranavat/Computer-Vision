{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e7ff3318",
      "metadata": {
        "id": "e7ff3318"
      },
      "source": [
        "\n",
        "# LunarLander RL Template: Q-Learning and DQN introduction\n",
        "\n",
        "This notebook provides a reinforcement learning scaffold for **LunarLander-v3** (discrete) in **Gymnasium**.\n",
        "\n",
        "You will be introduced to 2 different approaches:\n",
        "- **A) Discretized Tabular Q-Learning**: bins the continuous state into discrete buckets, then learns a dictionary-based Q-table.\n",
        "- **B) DQN (Deep Q-Network)**: uses your **MLP** to approximate the Q-function, with experience replay and a target network.\n",
        "\n",
        "You will notice one will perform much better than the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ec90ed",
      "metadata": {
        "id": "42ec90ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa93010-fd6e-4e45-a928-b277d00b0674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[install] gymnasium[box2d] failed; trying gymnasium and Box2D separately.\n",
            "Setup complete. Continue below.\n"
          ]
        }
      ],
      "source": [
        "#@title Environment setup for Colab\n",
        "# This cell sets up all dependencies for the LunarLander notebook on Google Colab.\n",
        "import sys, subprocess, os\n",
        "\n",
        "def pipi(*args):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *args])\n",
        "\n",
        "# Upgrade base tools\n",
        "pipi(\"--upgrade\", \"pip\", \"setuptools\", \"wheel\")\n",
        "\n",
        "# Gymnasium + Box2D\n",
        "try:\n",
        "    pipi(\"gymnasium[box2d]\")\n",
        "    try:\n",
        "        pipi(\"box2d-py\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"[install] box2d-py failed; using Box2D fallback.\")\n",
        "        pipi(\"Box2D\")\n",
        "except subprocess.CalledProcessError:\n",
        "    print(\"[install] gymnasium[box2d] failed; trying gymnasium and Box2D separately.\")\n",
        "    pipi(\"gymnasium\")\n",
        "    pipi(\"Box2D\")\n",
        "\n",
        "# Rendering / video / DL\n",
        "pipi(\"pygame\", \"imageio\", \"imageio-ffmpeg\", \"matplotlib\", \"torch\")\n",
        "\n",
        "print(\"Setup complete. Continue below.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a3bfb7",
      "metadata": {
        "id": "04a3bfb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db50e35b-c848-4462-d3a0-60e1b1c63ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, glob, random, math, time\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, Optional, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "from IPython.display import Video, display\n",
        "\n",
        "# ==== Global Configuration ====\n",
        "ENV_ID = \"LunarLander-v3\"       # Discrete environment\n",
        "SEED = 42\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# On Colab, store videos in /content for easy preview\n",
        "VIDEO_DIR = \"/content/videos\"\n",
        "os.makedirs(VIDEO_DIR, exist_ok=True)\n",
        "\n",
        "MAX_STEPS = 2500\n",
        "RNG = np.random.default_rng(SEED)\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if DEVICE == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some helper functions"
      ],
      "metadata": {
        "id": "tYDQka0i_I8m"
      },
      "id": "tYDQka0i_I8m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a0cec7",
      "metadata": {
        "id": "e3a0cec7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_env(env_id: str = ENV_ID, seed: int = SEED, render_mode: Optional[str] = None):\n",
        "    \"\"\"Create and seed a Gymnasium environment with a safe fallback.\"\"\"\n",
        "    try:\n",
        "        env = gym.make(env_id, render_mode=render_mode)\n",
        "    except Exception as e:\n",
        "        print(f\"[make_env] Could not create '{env_id}' ({e}). Falling back to 'LunarLander-v3'.\")\n",
        "        env = gym.make(\"LunarLander-v3\", render_mode=render_mode)\n",
        "\n",
        "    try:\n",
        "        env.reset(seed=seed)\n",
        "    except TypeError:\n",
        "        env.reset()\n",
        "    try:\n",
        "        env.action_space.seed(seed)\n",
        "        env.observation_space.seed(seed)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return env\n",
        "\n",
        "\n",
        "def rollout_episode(env, policy: Callable, max_steps: int = MAX_STEPS, capture_frames: bool = False):\n",
        "    \"\"\"Run a single episode with the provided policy callable: action = policy(obs, action_space).\"\"\"\n",
        "    frames = []\n",
        "    obs, info = env.reset(seed=SEED)\n",
        "    total_reward = 0.0\n",
        "    for t in range(max_steps):\n",
        "        if capture_frames and hasattr(env, \"render\"):\n",
        "            frame = env.render()\n",
        "            if frame is not None:\n",
        "                frames.append(frame)\n",
        "        action = policy(obs, env.action_space)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        total_reward += float(reward)\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "    return total_reward, frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30e5d0eb",
      "metadata": {
        "id": "30e5d0eb"
      },
      "outputs": [],
      "source": [
        "\n",
        "from collections import deque\n",
        "\n",
        "@dataclass\n",
        "class RewardTracker:\n",
        "    window: int = 100\n",
        "    def __post_init__(self):\n",
        "        self.history = []\n",
        "        self._dq = deque(maxlen=self.window)\n",
        "    def update(self, ret: float):\n",
        "        self.history.append(ret)\n",
        "        self._dq.append(ret)\n",
        "    @property\n",
        "    def moving_avg(self) -> float:\n",
        "        return float(np.mean(self._dq)) if self._dq else 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d8e344",
      "metadata": {
        "id": "c6d8e344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "ffca9e5d-4007-429a-a7eb-028042968876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode return: -351.16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls loop autoplay  >\n",
              " <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAXABtZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzE5MSA0NjEzYWMzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyNCAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAGd2WIhAAz//727L4FNhTIUJcRLMXaSnA+KqSAgHc0+h4/w8ca2APzOrpyzaYXYw3e3La5EqSascfxKazBLuJ19Hu1pdo8Op+yqKGYk0zDxA5zK2Xol2k1DwUAdO241xpqNdBQOOnKFdAL/QdC1B47I93LqdszqSkn/rYaGbthSwA25Zk6MGLx9s1kZKsn1EpuOX6jftEwv+p1fs9JEQ5HbNhKTDn5C6j95TqcoU+KZYf44jVWABxKe8HDYBP3L9cQdXeYYAAAAwAAHCMb0wsvbjNuztvFmnS4JVAAAcAK1ZB4SAO4O8Q4U4ppHyPFqN0uwIGIJvxz+nlxBAdrpdcFF8XHRNKe100IrirGij9ku6+O1Z4T+45y8z7TEdOSsUaPwZEfGuZ+9pc+RHwwXnnUNaV/ZTZL0P0o32XRiq5pqjkDX7sdJ+I/xqmKnc1s8kTLxYGq1XZXNZdc17ie9YIKP+g7fXgHJN731RPChQLVNwVhiMvgjk2kZBfKvYbP8gbXSqkfAQbdZvXTPyd6r+ywwC4CzpcTXrmNn0g9BgRgK6HSNnVii4lJ1T6x3aZoS8tPlT8J2u418XnOQ9hnjkiDKQB7ewd4Bnhdpd/xFFGnzD4k+5SdMEuMC7fmZfMBYg/t9tn/TQPwU5OLQ2I7T87CjaT214gP76upXxqaOxrDhjYZPZF/Ml2kas4J9c2PShpHPOUHNFpldGSWjqA+rxxZtMn5c+VHM007tnWVaKGvz78nkAw6LK2xlZUlFmwTCo7GJqVECG0GB8pefMTEslpUkVt91a0nLqnRmZH66oI9p8X2DSL1tZ/hlvL/Z8VJOYm0p74hoX2cZfUhE89vI+c2IzoCkCc1D+K1FflyikW1qXDoq+4mjDI1YGB+05OIzia4Z8mBmjMhe2un09cTJBLgNuPKo68J85vnSRTVK7z45LIe/+j1R2bXJeIUcNlRjNLIyw3aXmgEWd7QAZD/dG69Px4ya9zZJRLKdO+iQD0RzMUDxpwVlAR0p4fs6v/NnWLSvBJmp/G46czbQD3PCkHdpnTW0vxyH3W0VpONG8XRLPW5g1WQY/dwFCIUi+SEgXiK+X3V6+reLukmqWo8gDgb543IhOFi3V163ajy+cHtmQYkjN3alx9sBe4bnIXtur5IzftaKmMPmIrqejMFnV2OPfHDEcHv20n1ZqqmHychvlrEKjqEBzdyMBj+1pZAcHq8Bc1/JQg4OrratjWcDc7nUKt4C0X7whFefnlPrPkjM22abKPidfMUj8DygWWCXqTpv5Ye2lSX7kTVMHOqvimqv+kMBA5wn49Qx/stkOWwtcPqXkOzdRKxVlXxi1TvZUvV9eepeHHdacwATXEoVBwxuvM1nuzK2WoIk4xzu2TrI2JOPa/6MTbwbJucvjKnEqEpEOZ7a4ScZi+S0VqEMjzPCMxd4qLets6HMwd/dEIBF9nEMvpG1frBGmKkFSkOy/OI0qMgv2UvGxh6lV49kR2E9kLF8Na5D7TCKr69qpM0gAAC7/zdzhVlU7WRuNboC7TOnbHZCIgvo//t9a3gUNvO9FVYeFrNppZwnnbpeSgiMSXohEZmWkdg79gO0EYPqAAA4v5FshByIEuDVtIlYp/1tUYLWJRTRhU2psxzq3kwB0cjX8/E4DziJ6m+UI7H1lXWWeGgXbyORL+07S9EBTo95cIqYCiU1m8JYsHRM5H2j13sqaX/8NczvWFAIskt+9ooZLrJu6pZx3pynQactbMCrmq+2LsYGkrMf6KCbpS7l55YR4bQ+vUHEIIoZtycOplbhzO6HDoGypA/e8giPJ1lyQAKyi1Y6R6q0dHHss9jUpfHaLcGdn6utocHFT1KbKiTZbLgc+DXdAEymMaxYzyxnZANe138AgwDzX2ivuAN9fL2rbLydTD1BJVvlPNeWskQNszHPmn1oA82p/jBwa98mdVYkyWXcOscZSszgEb1qwzxEmi3dG13R6OFRw3MLgnYrek6qBynB6Ffib6v66TYhzz4zVvJnCaC0rSqK5ZCpHVBzc13IhmFgKEdeF57ptogWLNnwq5CYgJsQ0/5E/7XL8ecgHj7dX/69IVuFf+0Ge/WLrLFEpDrWoYxC1Z8R9lTzfMm/vU33HvNpQt7s08D4S6rregaUAAOztsuItGWOsS49URWbNMn2nbM7rvqHw4zp9o9ReT7RvyXrZZS0idBLCMgAAADACwhAAABMkGaJGxDP/6eKkZcJc//QJw4ufUgAzz/2N8gzGpgAUsv0vvacn+VY8ST+uxqqPA80wCpOlgJAXAAAAw877talUkFz9g/Cp4RKVklNCkhPytZzUqvbNsS9dOofz1wlwlhV4Z0XXPB3K/ZzlT4lH4/+5Yhmp1SPiozfodOZ+kBbwi5rNjztkoKxwfx6gxpPnUHF73K5wOe4WwyB498qQZeZVOx7UVmGrwNRrk5nhkEYCQdG2TWtjipjH/68nXPFKhy0BsdBKXK2f2wqC3srQi2N3TlbDQnXa+WX0a2/un/FKC8RrrhqsP0OYJIx4h3/2LWk77tMtJrdbVsdvwAT22QhlqUmUo6wnqACMXnzPnbwFfcrysrfyS7cmv66adwE6CdJA/hn3fFpQaJn5Esw+ty4K0S8AAAAE1BnkJ4hH8PSMTLQkCi8iQ7HtACPFFCYvTTQDD7OTOaYTo2EvHVegly7nYUCWeAfKnUzVA6kmWHTRDhz77zL9BfO49V03VZKxLoz4wk4QAAAD8BnmF0R/8VFzJQp46fySZbPNp+kO8YgAsT0dnxgcmZn694AI5teTECB1+byrSMvi6CQgEtTjgVorjfBBgABDwAAABnAZ5jakf/FLAbkWAOWxE67s4owfMmzQ33k4rU/Xa2Ub1GsB8chKUiXeDW0O6ZKQqU/t036YhbYVNizVbkBl7fVYc+2gRp9HufbHgH0Q3R1yF9tyzk7L55S4qPawxLAQmYlD8o2jsFBQAAAKhBmmhJqEFomUwIZ//+ni3Y/S7DtZ7DAMmSMnSWsR+bCUtTxp/mYjpHoXFDkFhSNYz2uahpCUj4zfKa0sWeJJAADlQAAAMDMBjYSjAp/0ZJAFKegTsuBXu2qZboMn5ItA9J3lBZUCeLp/KfKS6UDuMvfpuZK6EIFCuOC179czfdYINhVp4E8ILYcJStX5rzg9R6W2MKz1b8MOAqkxy+NGii/kmjMTKADjkAAABuQZ6GRREsI/8PaMTHHMC3SAGsFJamJBSCdeIHxWdbKaMU2mnGTbVOcA8TYW0+we0/BHgBY3xilwzFO8dTo2Dx+bIYpznKgGyB5snO3gYsVYjujVXKSOBuzrqf11sJvG1I6W0/BwB6H5yQUNnAWUEAAAA+AZ6ldEf/FQVsG0yU/XCk7D2CBJtacL+xuAEJ267YaQkmychJyLVAB2GiU3druaSEL1GSHSXVtSdYTThlgxcAAABUAZ6nakf/EstKfCgoALKs+/hEukYH0Pn66SqSf+p0gV6xR4YZJCOCHw89ef6SqzvWSEmmUt2cCh+g04HYasYlaOGkkwBD+v7qVfxgbqrR9jkvxhvQAAAAnEGarEmoQWyZTAhf//6MxCb4Zmy8q2jnzCXnP/qCJaCe4uGpiAAAAwAAMVzfgO4wKb1AAB70gnWM+bZ94D70m+ZmP1h/XkeFR77talVCtzEhDE6oykM8t5hEx9aZXQYrKDCRJ5K3NVyeCu/LO7BRAckwb0w0/QEE1eOHpgfpcEc5LvXB81/nIVMYooONbjBnogzgYMRqYYGCTsBKwAAAAF9BnspFFSwj/w4KGvQSBIyIomUB/3lwDclDtRaT/Aen/4AHBsFdoSE32UeesQxAGSXTJ3OfpXtaHc8pDlhA2+ElybP4Ud2XFIr+35LuP2OrP7Br1GttQQd+MoMeyjYGFQAAAFMBnul0R/8TKKNGHwNh0Nx5gKXXAAF/rISM4gC2vYMhGJW8FwO+wEAWN0mD6nxogO7pvE2TnMqtMsAduVEuJCQBAnIClqq/SGs6ImWePKJbt8aCtgAAAF4BnutqR/8S7ddVWoulYeRUAKtawV82Jj+t3k514b8byHHgk0q4q/hC/SKDdAv3iVG/eS9+eU91uE1bgJK0ZZxj1I43NQky048+9qr1r9I5s94jCVFvosqqwuVSGE3AAAAAi0Ga70moQWyZTAhn//6eI1x0SMoYZrw7f832sOXcv37+iWwAAAnm9NuzSPr8AFK89h93bU8LfEomGBXMPbAT6GEBqBGz7WUsXg+XOckhAxkuAfYNaidY9w/LAAKpshxKtSwOoT7gtZxVNwtxI5mMQc1e3hEduz0DROpZhiaHZ0kw9Jifqm9TlEcssW0AAAB3QZ8NRRUsI/8OBL6xB8kOQAOCXVWuVDcPDwOmY//juWQonr/DI0n0iSoh0O/LCk077RnuFNfQUBEorgZd6vE9Ast7iAxAH7G88qsbDZA5wEYK5cnPSDTbfh+Nq9E2q2V9Erg/FKo0gbgdzom8lJlr81R3D8Z0MuEAAABiAZ8uakf/E1f4AKIuKgaXhApXJyUsa9Oiuu5viMIwTEc113AGHWEzvif5MVgtaRK0UP7872xQatJ2xIxRcb9tciE+KDzuNbRz+iHoQR5zce3Bj0oOndulCXIsaPDTVDAqCDkAAACUQZszSahBbJlMCGf//p4UVx0H3wAOWIc9Zv5WI5glRp7COjx/QgAADpwnxPJKU+7apnFK9YVYM+cVAOtygzSYCIVvSJrpJ4DMkiEJ3c7opbTikBloxFWq8a/9If8QFk6goxkVtrTe5P94SriRVeTiuf9T1Z0FL5R/qwH+rCxzMalM22issyTqgIxSZQFwrRm4I4qCpgAAAHVBn1FFFSwj/wunBjAC29tVUPq23is88Jhqhr8y4B8l/ksoEAGXrab9CRqDOv1DreHLq7GpOMIv9n7ZIGL8kOvpYG1hVdQP2Xrg7Yf6x5Gr02T5NrTqJv9oo2cv1840bR+cuDAQyIwlr4FwT/u45TRmSfimRHwAAABlAZ9wdEf/EA8yGA2uE0Cvn8ABGAn50cF1CNnwv4sBH2hY/R1NsHuzLtO0MLA4XuicN1nl9lqmPvrNtTeEHI8m+GbvFfStuT9BTw2vy/OItARSeADOVCcomH4FkOLOmhusd3sgd0EAAABwAZ9yakf/EAj5HpIiLtmQY3G6aH9AC1zP3oy/kXUb3UmXc1tOe83/+Yut8RGqcTy25D2K0jwDqgfHVu3ckg1LCSQOfexf+yDzIO3cYZqeNUhCiDJr6CTu0HOaQved6GMQz+jXuto+jE1Y+eMm8JQP8AAAAH9Bm3dJqEFsmUwIZ//+nhRXG2nfAA5Y2rMNfCeMqERHv28JRp7COjx/QgAAAwKmd7tqmxzIPkiTOvT4xm1qyDiIU9ghgmHo+5bCfl9PRrCZO6w854tsmjn7G6WM9wo63CL4vyoz4W4FgQ4fdmtYpVMb6j8q2D00dl1o5GK0mCTgAAAAVEGflUUVLCP/C5vYwAt4dFISTzsf9cuTIWkxzJsc87gSZKgdRtFiv4fl/jWJybN/zAByGc2mYTIxenXm3gUs0Dmx3uw1T+dW4FXKoomaVL8FeVg9oQAAAEMBn7R0R/8QJArhe6o8RY1ws1QApwKVxyU6pqtqbEfKxGvgCTCL6ANXimTvkDugpOYwBHO3cYkBRgFISThjPtWQULKAAAAATgGftmpH/xAI+FKthlngAG/VddsM2miPlMISbGbpgFMbR8xbMkmoYB2Tsq/1sMM9A9dfe0O3A40cuNFN0brhXZRJ+nBJutcnHkKUaogGzQAAAFdBm7tJqEFsmUwIZ//+nhSu5VqJGRwA1+ZxCQnnmj5D2etUHIM1voP1sESyNpHPHnawZ4y3nT6SSteWGOmqjdHmotnpQoNhBKAAVrixxMmpUcnENvyM/IEAAABMQZ/ZRRUsI/8JPulvfvEDmN9Oz1LHErA8AAUSCaN/rFBHMfiyWS853uff94gRUTCJH+PKvgZhxeLMEmGtwgW5guqLHV/iict4nqDlgAAAAEMBn/h0R/8NlGreRkkTbXRAF+3fkALG/Vsbqzo6MqkEgziRV94NHocsk1hMaEDXCNSFA3MGdQbL5ooYVCYOnjfjCUGFAAAAXQGf+mpH/xBGKwAWztJL2xXHN4HyUdQ6/Wsfu9dug9yAp11bH3rMPZX98iQ6eV0yEYLzmWMJKc935vJ6oBgh5+m8FgTgkXMuKEyYUGYE7+Nb8y1w+FLQL/p4yQgg4AAAAKJBm/9JqEFsmUwIZ//+nhRPHhhOiAH9i1GeYXAfNBruGzrjPEbEwiIKyTQAAvkn8hKV77tqmYDEGWCPCd6o2E3czYahrIVd4FTILSropCy2BXxsoxCyg3O8B8DKhgoVPfmMT+usXjBb4LJkQV8OciEX2Vw6bypeg/yFiJEUbd3pDn6IEtvaGskUQqq/9Hh51eF9YcFqa4QfIZ6ThJ0OT7bMIeEAAABjQZ4dRRUsI/8LptIAEe35ZVSY3Dpvk32JDEfvdUngUGxsnAoA46AfYqiBFOv3ZlHIK/uDyUQjgNfNz2hSUVua+IUw3Ae8XM2SyH9aEKCFwgH2tH5qhdyXQUbAfpaKtHP9nQHTAAAARAGePHRH/xAkL1yR7+bUvTIQBUVbj5ReAIctGOXbmIoYnoAS7BklB4IssUT4gUDBKq/oG3kcSd2N+WflTgapz1P8xg3oAAAAYAGePmpH/xAI+R5TOgAh6NGFmzrRNctVK0qJefBnuv26seKYBFohPiBCrR2NFP/CsnPqTsU6dkh4fPFVnm8isjxkEb+/TDLynfmfjWkCMI5vEYLXMphpPOq2j3Iy/18BwQAAAHlBmiNJqEFsmUwIZ//+nhRdUkp7JnGxJHACUVnG8cSOAONPePIkEAAAIWzvu2qbCuE/hzCz2z/DYIOJYf7irKrYOCAgau+oCw5Zx2sXMDs9RnPGuN4czSwCoc4f3wLNjZb8uL+VfFguUVqC1pge+yZAB/GkahbrzCghAAAAS0GeQUUVLCP/CaXqnVDO0gDKWBGo1rciWkJVjTzOktFJsSlwyLHIRwGvm48AAvvvgezL0r5nHnQZ6SlrPbQNQtL6fVJJFTGmGfCrgAAAAEIBnmB0R/8NvQEPzBBwARxdzCnjqsVXQsBZ1TetEcqW/sN/wYPCzoYMcpd2x7dVNdhTmC8z1ZvPmOLDUutMT7Wg9IEAAABdAZ5iakf/Du/zUAG5jvsBtYnwEf7z0IyXhRKsfK2i5oPpJicjIL9K6QnxuO3ZDLP8BrzcyhklwvxgTf0aYSlTOcwPQxFlfyH7s5AQlTNZWi7fgfYkSCLLEh9UsDpgAAAAb0GaZ0moQWyZTAhn//6eFLM/vx7V88aKgAKp5E6hL232xrz6Ac5zK1Y6kRHBKJhhJewABgXpe21LflY+M/gINqD5koPoPLt58zUi9eejdBLOYaIvnG3vq1IVDuNs9kTFj6wcduJr8kMp0n03fPRQQQAAAFdBnoVFFSwj/wmyJerHTX51it07MhU8O7Lx7XuK0AQjIfHopNkpEL2osWxaul8Qy78FYfSVyClQndTku/M8+35PNJXqK2GDk+gDfDNl34d9STiAYx9FAu8AAABAAZ6kdEf/Db0OgzlGNin/bkUzFDz+rgA4rI/LB2QO0SMC+mHNlvcWMFXjNosxV6mHTJdCAoyOyDLNy2IiXc0OmQAAAEEBnqZqR/8NqjzRRPE0vHu9J+u4zpxewBt9inhvmDhbV7WQwbQRFUUcpkjYAm1m+KDv701ai5cMgrG/Gko/GfQTMQAAAJ5BmqtJqEFsmUwIZ//+nhRPeJWPsgATLzgs9EYN92AI8aXlZtVdqB3N9/0fZPIUQZoU3EP4SnQJx+qqoUZ4Y17qougAAbGZf/KjEtnq+kDmQavKRvjr13p8nd2Gjkk59kqlulO921TN0E/453VNdFwqAsL8q3Nthoz91ZyEwp7xddbc6go8GJ5eZ4Byk8yONHPFVjZ12sUSZRpNAYx7QAAAAEtBnslFFSwj/wm0kaAsN/AYAJxwysgaFwXM4bezoeF5S+55EJc7K3tq+wYm/HM2Oua5bjMn8Or3L3K5B6wWACRsJkDNDUZyfkQg7oAAAABDAZ7odEf/DuK3EAHASP01Z6+2g5LClq1kmkl481nUwZPopHceqaSvubBjNbuppR1ENdCwOG//XEOtMl85uwC7QV4EvQAAAEsBnupqR/8NrjEdABozUXQmYJNfCwGoy7jMofV9Z6sTBY/d+Y2YrIUNQw2ChzFQULX3ZU0MDLFSyIHpPqy7NAemg3i7iX6tMjk4IuAAAADIQZrvSahBbJlMCF///oy5pNnABcYlmyRW3xNq5aVecutRGLzat3dDxBit9F9uJyVOcwLs2BIWpVIPHQxhNSXNeaWIj4em8XLmg+OC+eLjFTBr8DAK3bgo0bAl+T44t5rnyEoP6EnrEDcjCeq6fVLE8Pw9jj+TKAAABgIfEAy8tTAMKYwA2Sto//u921TQNw3un/1g360Y/cczGVKaZghbtEbTaFy9lGQ7eTQz+oaOGQhEVHxnz+pE52UeHYT7hGZ2zjSNZrz8H+AAAABdQZ8NRRUsI/8LgiJggteLe4VSfnUrvPgY4wcaHFDp54AceexzFjaKQZ/6MlA847bUmxL9oDAeOYM51r7eqInVOvYYogHvfj58JJ6dfkDP0nXWcKDxCw8aut75+EnBAAAATwGfLHRH/w2aDOoYnDaoUypCER4EQyYANcxjyXw9pR3OIUAA3hAjj7lOlYJGXlubWgFPtxHSjprhphcSYZZDZQ4qxLgkE43Y0VZxC2LAIOEAAABPAZ8uakf/DynVqmQCXneiNJqjVyWwUuqPYMbS6cCHXxptel6h5enBxIwcvZC18AWDRbUAnzdKeilmw/I03T4kaQLBTO255S433XHWMv1jmwAAAOBBmzNJqEFsmUwIX//+jLqk3868AJXvNu0QECfna9u1ex82v7rvuoB5rrZcl3P0LFknzgQV5rBB+hDhlwR8km8+FyFaAaZ20iqsiyz3e2ELF24gdrIMWx0y0Ss9nskdd0l7r8kM3irr0DDIuGXwpL3Nh/mIfXDWrcO2oOFtuZbbE7+KcvEjFJ80rpM00AA1lAbDl65yXOFu1LHPrY5UR8Ue6UgR+x/LXu2qa3S5RrsVve0oCXE5gF4EaZzFtvmBbxx5gSp3qfxEXIFRrn23qDJY7jPdJAgsEGeRgqBR8eejLgAAAFtBn1FFFSwj/wtXd5HUaHaMzwAP5vaqofV8774GMogOiyAmO64iD4v7sCW2gGR3K87qhLTDgK8Pi+RKO7pnyoWoTqT9sW74AP06IVOdNneftSrU88p1+MOwoIWAAAAARgGfcHRH/w/29UebtHfDjWIHRKsvEKNnp1IzwKJHeUcp3EGXv75gBtaqhvT1AvaFwQQq+EcGUmA916dJH0LVpNvNiesqC2kAAABLAZ9yakf/D/yIUZDosVhs0q/4B0AAcbchvE9Ju4fT92NVcV2WsVU9ZuxrbfjwQn50RDO8ATxov+FCRvs5TjP0mPSytJtTNw44iKuAAAAA50GbdkmoQWyZTAhf//6Mukl/ZLENGPQAmFC/+KdXcSk+BninnlnXcZ4sKKK6ur6k34TdVVOyYhwuRlSCT3za5WqirxdEIP78DROj/HM7vSAQmW0JceM/+ZCed/ZwO60mtJkVguaqDRMPxtKAqdgSGO/NZSxnbJp5Aax1iPEIjyQ/j55w9mIPQvNjDB88b3LfsgUYD5++ngdiaoLDWLOU6BsnXiU21/Pwdw+bINBzMGYzfkIyt4l5dW5owMJEWxZkR6GjOcAtWRatChvOKYTuU8CFlE0RgS9XCpRkB+fMuYNpOys8CYGUMAAAAGdBn5RFFSwj/wtPL7lXXCAD88s1Tbm06n56NPaEMcidE31VBTPPDBUNBQ2wD02w0dyLk99KsJtlC2VFA/2Fff7kw+FHTh8WTx+SKMiSLuGPJuWRIiABB6wqt3PWfFv70R4BF/31GALLAAAAYQGftWpH/w/Liiw6wmottUmtgsewoSzBOdACzsJMHSoAgtQHCeb7wTYCn6NSWoToJK5O+3/zMlbuS/yZ0w4iYT8nzVRJ7yaBIVbLlaFmA5hRJyijudTc9xLNBxsUZjYMGpAAAAFdQZu6SahBbJlMCF///oy6pN/qRLCfvY9ExIAH7rV1fgP2wixFg5sL8C7QGXwNfGTd/+r9G3W/J6domtdWklWQKk1pCFjlExVF/pSsBlfObxdq0tC0qun6vyo98Wr3eBfUIsmpqXH8Nct4IC7djTFaHj/oAhKiZWq+mtOQ+rq8kj15uUmRqF8C8Su9vow5sAAROezNURbqD7Ne6N5qmzsZQ6WAZ6m+cnrKTHazRC2zfzTsv1VfyEHFTm1tk4m8QeI7aQMkOe8u+ueXo1XKSWtuMK4ov0MaJw76BRYv5YivSncomdwEP9W+d+JVgiwqECn59Qf05rPUekenEEDY+9rHjGczxoV0zOpm/wUrxUbivc/f8yEypzbibyBPhx0ZeJ7Yx2Xe7j/5Pet44zaUEUaSOEnD3igPpiDArkczkFtBnwmgtdYYk9OxKvUhd1Le1Wi0vDnrlR7M7HAN5DApIQAAALpBn9hFFSwj/wuIcWc/A5AJSg7ucBGeVcNPK2ZbdC6FbQ0meRcva56tncLedH3PyW17mEE+Y9/LdwmJAw9qW6UCkj/fh4GWo2vuiSnivjWylvNBiaCstfZcaLouDftrqcCR/2+WgTYZe+nmP5wGCYnMCrzEW8Ci2fTh+2+7rZutN32Dy7cw7GuHe4yTTQEmK+d9Ar9r00SOM8RJfGb+1QzyKA8284zrYcFuUtx+P5/hXzLs1g0EmgGCBJ0AAABbAZ/3dEf/D/bzw/ie8P+aiAEynT7fQo7eexskuncwwJXcnLaEKU11zWYunsnj5RjJZqDKXQaWOVj357phT3YnpeFdoXMpR8lhvmUc2CbfmdJfxvI+2DX9msDlgAAAAJIBn/lqR/8QCVOgCg1pLUBTnLc27DffcBGH+a+jGzRd8cp3zpneFhMhdU7b2W8eecjIetFShC59zsRJWuQWfjMAzweNuFphelK550MW+20iabhMn5dOAjQpQ/PxI5QkEQlPc1bhUWhLs5TmUPmXwOS4yG4YVawLzKlG59Dz5iKACUgEVIrOZwR3eR0jZSoUGbAz4QAAAS1Bm/xJqEFsmUwUTC///oy6pN/n4dOZ5dMEuk/O+mAFmkkDJlS29C0i6UbpirJnBbBYHBOrhT/7VFs8CvKVpbvxjHY2CTG5oIAzpO4AgfrMM5N8kr+Olv/p8d+RQOLiLm9/o/27Ja+T6IAOkUffS1GbQjXwCqC7Jz8aWNNHNgShkTYQ+xXOMuILBmP/bWMPeG/mEWLc1y4DvYZX3czuYA5eaFZ9qa2AbsP/0ZpuNaqfFXXIxSQyDNDQt4shfOuw069ZHqz+NSsAw5FMHehzhvWfzOW9Ewzf3Abs/CcSN+lESsNLfgGEdv44w2s0YEjMwazmAYs0v1pNKyzg+Qhc4QafW8BTSopcLGGJgYKQm4updRPv6jpmmVc2oQoQ+9miGgC5rj/Jzo8BT+0g96xMAAAAkAGeG2pH/xAIwtYONADovY7zgADg9u4oI6NUbKiOxkvy/H0ULBkbAAraR5WrCO3AvM0TtLiGOoTHhTeC1EjGO/f1MrXrf79F73wV6y+pLj6Iq4wVWU4kRff21UjcsgDnXnr/DfC6BHsq9CJcn0lWxVyBChIhXHELckTsK1lAQp+MsLW8Pgbefl8JQc/mLOIOmQAAATtBmh9J4QpSZTAhf/6Mt2BP6CiWUR6vQBHvFmYlclUV3PNGUCmkoylXCb0CIIOBmqWgsiQmz53Eo7l/y035OXPZqOhLvm8iqP61iXcAAtwjSvRHUOFetGgY5Fq6mlFXDEtiZTwJj+GB99FNbJ1knOuN5Wt+ROpMG5KnvPkSPOjXzr8zaqEKIgct0vdt8Hex5+W+84wGWAQSgSLPqdUw1JUADsS7OJQbtnjNi7n8xnNC5xhL6+nDsI+nPmHszK5gI7HOWJtceYwNNEHh8p5nS0Vdg6CL2UA6Pf+DzniuEjCJRLD9H803iiNStIOWwLxWLq3u4dDmMdiGgZLUVefxesJcAUVY6lqKkkNExp6AcpkYurTCaGvBEIj/DjzF14KjkkkYeeUdTpFlNfkpr5py5FWh7qAywMMXqCOZhJ0AAACdQZ49RTRMI/8Kg3IDF0il3CMlflwAXQTgtoDGpp2W9NZfidOJaC0OSJ1ejritbCZq2QJS/wvbk5WXTTtxe9A3B0I0owRvctprX3WN72eA63bZq8laCsX/Owsxd28rVKmomW+gWJ0X5pwwthXFkPDiD++V/gK351CmWg0mqYJJqHZKiQXwaiI0clxyXRHtU/93LcwCsa08XVZpD/YB6QAAAKsBnl5qR/8OvI97DGSLXKMi2702ivcAQPW0RAj2x0K5S/GSAJb9TWyAEnvERXB/41Tzd+k7t3j/1J5m536JpGP9zD7BQ5ktOZcrRjhfFhCGpuEd88vrzKXOZ9OW15yA8pQW9tysoLkfyec41GlQY9kHFtNuv0vvjdzhncKWylj3j9iMUAPmLBmM3YhsKd/RGZ5l0NOBxOyttlgE1vgRjhlLkHq6J+RTVOcAJuAAAAFRQZpDSahBaJlMCF///oy1Qw7l/yvT//BoATjwoG2K58Gc+AZ029v8jDaFW8OBFvLy3rMWdyQejjucyb2BNzyrd4GE3eJ/XMsEyM99OQSrZ1MIACp9pRzysDZwLGlHIVhWFjkVEycawn3NYIJL6R2YmW+vRYFo43szvHRSNiNazWkfPYdmKg1Iu+7WdeyaUuykBde7Px4jaEowBuchT3kyZlg3ryo5MD58tkwnNy6xyUjzFSbf4LA6D8AFMebJarH2eW13Bjr6Taenxlfh1IzCncL+YRKiNRIF4XEw1nu4leO+K8LRMDYFcnqjt+nDvJYQPLZv0IPAVOB0OlE97Jpw9EO2UdB2Dh6tGk/q6rxMc88glItjyGUt58KKmDT2OYXEEPgHVUyxagrkkGvyu020MxlyUTgOtDHO7w+Q3TsLuJ0tJJeG82jKcVTgT2ozAYRVQQAAALNBnmFFESwj/wmsRthPWEBQnrVoOXKD2qTXaAsopscxGfwgfiQAtmMR7H/MAV8pToXfffRQkUEbRD3B+jIHRYW4ZJgse5CMReoacbJ8VeYCvST3gcEuviujlwjch3WPmQ3mueYvcyYhr35NL2aDlhZo7bJHXTNOpl3XTQHQf4JTi1ggd+GS4rWUtXiN+gR6tUIdikuk2/mSWy8R5RvfDgp0Aj8PnqN8pYXw14CvgTQpMJPCDgAAAKcBnoB0R/8NoLtwAa5jH3k4QhDWDGyvItUsmbTekVFomKkFFc6guGG8xvTN9WZj3tAFJUhz/2cw4vC0p53i1udr9oorHKuZ+rQoaeNC98o4IIIkwN4195ijvfOT0UX3z66BlAd30xhcIknUhEFB8ZbVd9Fb2XxoU1AqEhHMnRQPs66p9zMt46fvHWIetDY9jJzxrFCA3QQTgKzXHSoTDzcBoQgBcOlCTwAAAJcBnoJqR/8MzUoy/ebyxykZ8S/lO3Knq6egBMhwJWqx9shJGviFMIclivNX0XyyVAfJgRhZ4exQf1e1D58wdD7+YSaoijRo240FjRTwDyvZXfZCtz6N/PUsc9Gj1tIHbrgcOMdsy30smYQ2rJsfmzqtxB/995JDwJ/+352p7zii6dxVwrpXc6D9NGsuWU+nHLqIzJRugAXcAAABEkGah0moQWyZTAhf//6Ms8dMKRIotn/fuPVcpnrAPW+kALINcxPLlwpZlvd9mRi0qz1H9E2QTQv5ctgrnwmSLZIwbecezxywJ+YOSwDOO6PggWvec+8Nk3+z+YtBjC9RBnlzsVnlbFfDdBQcZzSBF/3y5Hm/hUYvGh8rGY7m1HcIwisx7LOFmQ2/OAVC5PssYAeP31fYus87n80v8dkUXaLlaxB/Hq0095c9gluZLU5MBANBKlt8gjpOaUf4o/uV+sQR4GAAgeN45ZRNBzETc1NvPKsHHL3/DYDka86QhDNsJVpmu+uO5pjNSKJu04ulVLgWtJxlOp+D1nPCEqRXQ6vmUtpgISkfakJR+fGFJ1PJyQ8AAACtQZ6lRRUsI/8JyEb0ANekhB8YztPzN0CTemYvFdLLm9JWltt74oPTaR1N40ll+gg6vGbVlmv69uJavGNZSM7aTCRkvN52zT7aa8hfN1s8nDoqxyISUUmHH8jmwrRgTBAaV2CPss8PEf3j6D6r9TISculV3rsYvxxv7xuvwzHgAAxVNcWknouNl6Cw+vMXumx7dppyRAPhxYANpQXS0oaJDZDeO9VSXJeQMy4qFBEAAACfAZ7EdEf/DsvwdMAA0VvbFCAci7hpdPU/H2e63AoxYMjmk2M4yCIYODMF5Ts5HHWVPvRf9dqDCI+bGW5Dc3QUe9tG3iYcEoDhp2uPMRQ6itNYdkjMpRoozewSTiGsxcrDm2+65SPE3Fo9QjyYfUQrNA5H+GynZy5/Qdi6b3BSOeJ7pQSFLAG4CggSgMQIKZPtbf6hOwIsNcok8d1WSQdNAAAAqgGexmpH/w61BbQot2hbXayZIRgyFH2NVLYkjXgASNjaeDZv1lUumxcedk4vjDKdqIDOcKeaSOdDzFq2WqIx+gp8xhcpu73McZqT0HbC3KNnIQSJdQTepXmTnKR9IqaTbUhZ8pp7SzBqu1hKfJaQSKU8A3x+gqBX7QH/nAbjl0Qpt+ruPwjBib4cXxj8owp7hg63mkDVMeEAZixPbNwAk14W/3XG+x/D4DehAAAA3UGaykmoQWyZTAhX//44QBocn2Xj4VPPqYGUbjmd1/BmeQwATrlTE+JSehc8tXnGRPcmNJyQyXhIw3ltdLWUMLqAnAj9156UNrdvUseayl6zhtDuniw3K80XmWPOWqUqwqj0zjquEPfpz8ne3l7SCOjR6O7LTSeYXb4p7blF6bniPzVoi4HWtHZVK/087v/lI0Ad5VlO9QW5hhHflEHd1KlWBlM02Y5CZrtHTd27VfL71BFq/JLJEi4r6uRptnFxcMMx11zNn4nZmHa4DMmKYuorWWP4DNd9AM3QJ/nzAAAApkGe6EUVLCP/Ccp2wAtt4IRZsy29CpbYdHMXVd5aL2sdoQKLEHhxMCQNpYj5QsWRXGUgFpYevITNzj+zYD2VuOAaMakf71VIpQaXDPr2IV+IsU65X6tkkz1AUuU2aHSVnU5WoZr0IZMpUvmrPX9To2sUAqA3FgB9l0FB8cY2ie9wgXMRHY+UUfsSBthFKpQn4AVW6bMaTK34aj55bsP9uIRlcTMQCygAAACVAZ8Jakf/Duf4AIHNQXUBwnjCgRU4QcjX+GGgO0Ho8Jo1AjEqTkK1mFDCCnDXOz0O/P3LB5tyn9XltJebBokby1YlxadH3etDbqoNm8Hnh+s9Ue55gsveVnJ5sCMQmgWRpKcdxnNa/dBGRt1cO/FgITtN+9VCTK7SnEBDQHgaNLQ5AAFCAKl4yZC99dAIeZfSkmxEDLkAAADuQZsMSahBbJlMFEwr//44QAk3RNhYNjv2iyGFfwJtUBjX4qzc6ULbaVUd45Bl+zcdB0UlIu9Ne3/48oATTz99Wz6m1a5lvzWjvMnG3KvqGnOB6R/6PczROgt2eZEldMqRSdD2bCZdUFtnUDMwO8sbYC67W0I8O2eXOc1QTYpPmtBEcluCBIsvURBojyW8WPq00eXx6K2IlQ+Lhb3n9tQLunmcAdnWh68uCBQseYJX1vjyrxQe6ygrB14VSgfqQ1flBn5bNo2gVAuUzv/dtLpROQakuUuUvRHAHtYoqDXYNt3nD5c/R1KusuSYDcUm4AAAAJIBnytqR/8BWiEERAbHOnCCBHd1Bunq3+IASufA0k3NoD5/fEeGoTalJqPvt+Wo/vQI1sp1g77pFY1d56bxm6MjeDZmvukiwvQ5uqBndggGRdySTMBHe7z7WHO2kWd2178CIsB2eJBwjJj2wYXB9YcIb5bz3CQuCBx70CXcBoeLTFCHc9z82zNvFUUG41rA6ewLaAAAAPdBmy5J4QpSZTBSwr/+OEAI90Sp8UeIIWBlAXO9gBGzShOpOAoU8VnYH8nHkMMzkZOPAn/ysZFkWw/THgoQwXb5LyOqA2WoEgV7xoX5myKf7Hak/ZK1J+99YMvyzp8eXm85EN5tOc3WX4NzsmRUdq6/b4vTvP5oTG1eyQvYBlZnd52+N0tuNDTOLKi7LT71KZKMQdVXqFlaGhc0xgVwXxGxBGxc77N7nswU0cU8Uy6YKKiSMylGFhnjgAVqMklf249ZJr3HvuNg/SQkssLibse3A/6cgIwzEZyR0aW+lzG8eQO2GIqIMG0NdWeaZps0HQb3oHibzgoPAAAAjgGfTWpH/wEtjld7Dt0ZBXNACxEmnfELzg8KxNW5O4Y7cQ0kUd5Dzjo9DBdrfhWyysg7Jnphwbp8+sTAZ5x7IvLjoR9XMWyx3Xp+RWRHIRVfQUDYNHfiVfkptYcR9k76jHw+dSFyyUHLAgFHXJco1lMh8qNWZJZX+PPYAwGyLYozc5ZF14JqPMaXuCnGUMEAAAECQZtQSeEOiZTBRMK//jhAA3e/9JBhL0r71ouVwu2HIk2OgTnmtlR8AJVQm72S273OQZYyDJptVj5b9ZaSND61t1kDYDSmnBNP3b4g79zMNEuv+2n1E1Vg15OqJnDhO9khNxS878Wd7wc0+ZIRj6hkXMR2u4I66aPudEHlryNdZu4LUHbwgi1FMpuAMA6qsOLktjEE2VPxChNeS63YqtJL+VCp1/JcRJL/IqM4CxI1ArEmFEwuEAGTuaPbb03UvTi2bKdzdPp1/oM8sv24rMmaRxlKTEiIAvy0/ET7KqAUuWLWvXlWBxKPQog3xZpi+yCW7c4lPtHPNF/IPsaPNWB3oNSBAAAApQGfb2pH/wBz8qIg2hXjewaOg87OACccIHhnfofJLFPq3DfVuAnygh37W1gaSqt87fWXmEJKVkchsNnT16tHaH2M9JDoU4EBLj3a0HfVZPaK6QaUMT4zO65MiuiGJLscoUG05vzfwgRJm00aZFJfQdQVH9SE1T6p3AuySTh9+J89yP31yOnPxK10cfm3uyhAB9Fn6madwsF95aqmg7Ae4A4ugl/BFwAAAOdBm3FJ4Q8mUwIV//44QANjm15fxCX7ACSEqGmRjAFQkmBwXmGHeKrdAqKcWaka02EGhOM4BcTUmoEyxoH5eajUyzB6hzvuMbEhoWHypzLhlOAp2SvMydvrPbTNvCOaB2zCKgO/YWw5TVky9CG6BhTZxvkXHcIatQM6gN8xr+LZktdLSwHsZ2cDXi/vleKJql//+Q4MJVJXJ/8pR7QCJQp0ucakhMP1zSYAMJ6jn8ebvo2BFEpln6gZBEZ4k4vgdGwRs6cSzCHGv8UyAXCJ1PW9LY20gKRB6Ox8kGK37rxg5rBtK7QAUEAAAAEDQZuSSeEPJlMCFf/+OEAJNxLHH2EWdwAIg83HKz0vY9DlU8S5BTjr2mYW5zt+ybUSz1tvYoVnk9/JlWjg9Fv1KSmSYcWSqXOpMhn1yF1WttQd1WZK2jVrB4kj8aM5CtVcbnUbvqqMy6HB7UURtD710jVmEvX7dz/iRDvcRa32P0huC+B3ORKt0h+j9egBbLJTY8xkthNLdbbElP+5kvrLjpj7llu2Z83adFlRBCIIOxJAeBAsTGzldA6lF+vIe9OHS8lbmnqoEUKeEuTCMFz/Z61PlCLMYALS/lkw50yy+DZWAS/qzVh9+mtJvAF4r3+pSS+HhSPj+JnB4M2xzEYdqzKFBwAAAP1Bm7NJ4Q8mUwIV//44QBsrt8cGw8V4APxWqgv+AeN/tPtSHe8PlSWHYUttBz2y+MCzD8x14VrumJG1hkZXBbeXqWqX2HnRVYv6ZdvZQREkdUB8ciJHhiUbi/ujxBO2U2aP2fHtLc+Z23C1jV4PW4H2fweif3oKlZXj0R/vKl/3xIatM6vqahPDjg/qu/XaGzXpNt9k6+PQIDVgULkpQVE6zBTl74tDICER1pXumYyakh8OIdX7UQvoThJqEJI/J8X53HXGtzFL9d7JUQV/eVkpZcOgM3Mgi4xjAcnU98Iti5FN8XT+G/7kBVcaONRQibSR42k4X+HcJ8GMd4WcAAABAUGb1UnhDyZTBRE8K//+OFfAqYAW33mP0WQAoIX7DisiM1/uBjlg69w7CS9phU3urxkV/nGNDObgALdn3hXCPcv65iknF8nyTtJ6tJ6PBWT6ADK6zJJaXb3bcc2vejFHZhrhkVhvbav66BWeO0NkQuDexuO/ehRK52DsEtbL+exWLR+VrRDihrAZLY79iOwCI/rC8FVLGL6aMMVmNK6pgKWyBV7V9aCztJu2mydclhAtKe3iZJq+paTP0OvgFUSS2UEG8uy5a+0vCwPiW6WD/krthQiB0mYQX0htaIGO0qbn/4yd5ePdECU3xmlom8m87Ef8t6QHnu2NlH80jUA0tD5gAAAAzgGf9GpH/xAbY99ABB4NPFQphBwejlR0DrnEo3EiZtYMlaCcd2Pi9LKNeSaOb5W/OycZN0X/BMtc+P0DBthPBb/vF8SdDP4V3e7FeORnNKpvG06ybrmGc2a5vKUFWeWaG4fmiPfZWsMLG4pLtMdjRTkLBelQRIv7pC1ihSYZJjOhfCu7OVRLEIziV5ztnwqgTWNX43y9SXb/Jk7uRoU6TQUkv9jbl8tSjEvm5BcD71u/Hrnf5cT8yV7k9MqIgLgB+5r82JbJL0I7SvTIgOmBAAAA/EGb9knhDyZTAhX//jhX9PxCFGj3MQAmXNPlcRHcym/bPZJLFw2BAsXG4JCsYpf6jTaW0byaxP0JzZRbQlNu74uCcub4VeJmBzZ2LUgdL2Fj1jP26nVH4b3Bl/qZu3yuyDLl9+4pbPk2ztESjk7dNLpGYImYkneFfgOkZMUar92UtpaR1wdrZMQJFXrzuV/7P0pwoWTCjOkmWXlB9QdKT46lRZ3WBzkxuuO3lAiQSErIU0R4GVE/9lMPDbrGwHWjDj7XcW9MKw0lD++uRgr7c8lJ767A1AznkIZXI5bdcb8ENgNzcTdTivrJofL960OVRwiVkxpipJCF/IbFlAAAAOpBmhhJ4Q8mUwURPCv//jhACXcQ6+a8+w8AC3YDrDy4AyE1YitBgD+n5/a/6f+icRt1Rpmy8BgZY4Xf1vY942ZnY7tNI6nFXut47qmrtbngPOcmDxIJAZ9pZdLHtTqzeUiczSaPRi+Hq3yu98Wdy7DyCQddO9tygXF/+ZmLojXKAlobz31zSa3e5KbBynPNL38uE2OmgMUxAr8seiYpo1mH6ethmbSv4VwQ1fhlVbmslJPBFIXZg1Vl9wAGUriAO8bpXSAWGoHCd4QfhnV+3ABat2SaOlXFKwTwuzQfXMPGFcTFLfzoBpNlwccAAACSAZ43akf/AT7MwD8ABQCi2KDVpO2JGKLjftrmraf0TY0fHbYlFNjFRPZP11WzePAMdLQERRrB32btnFqqdbBjdF/lEeBatnXJTQVvMmOg+XCBxOnFWj/PX3RJCae2TNN97lgBsn52nn5ZrKLNsNKYXBYHCmtPNT94ItG3opEDyNXzbjiz5tsz9Zi5DDfnkNU0JD0AAAEgQZo6SeEPJlMFPCv//jhACWn7JIzXXg/1p4gBCnlRRvN/Js7TEommn6HSr1m2pr6ideNMKTnReIiUQCixYX+JoA4VOsshFZJZQgWLetb9fIpwqs7fb7zRpjB810csHCfccM4np2BsrBSbTOvwCiwmvxlTV/f12/+/B+ZTDB5u7AJbDYgAgsPjQJRKhZlZwHh0aFbosRKuAZx456CB8Beq5lC5CYCPMcV1fgcsKmZC8z64WBvcBNZPMQqzdmx8lRpwHJ9mPA56Nfd559rpV943s0DtaxX4T65c7hcq0f7/+5yqAOa79rYvGLr2nVyUyQ8JoBsIKGWV5+wAyoEk2t+1tNLSwG9mZblhhjbHMzomxU8KqGx3WCW4Zj7Ow6tqQDpgAAAAwgGeWWpH/wNe+TAHCpfVe29fYMsINujIGH59F1/6wsyb8nfohqbyPXNwPFLa7+cb5cRPYfT5hxTv4TslBgmS8rO2cfXdNIryYBfSGbnOpv9pNGeqdbFCp/nRyjdJq26BJaKUZH/6DDijV9QYG1TgHSpvPvORtATLr0JxOgw1jgxmPa1VMNtdVNz0JGNF+5D9rag6Yr5gh4hhTAotWu1CbiSGBvqQEvkSA0Qxv+1d1TveLBcanumIskboXXY6BKUD60PnAAABCEGaW0nhDyZTAhX//jhAA3LFAgCJjSoc86aEPQgN5n41VdRICFT+GxgBzluIYwXNY//2aupNxoaqKoudpUgHBAhFW6VZdSJVAGX5Lp+bKArgEySNKlwgQ9UttfW4HLsz02XvXV0myderfeX5Dtb9af0BL8JyQsWXb1Utxf4SPFesGQaQXkW2cqXGCn21zuDOsr/OJglQBMC9P/WFuuZXuMmoall8jPpCKp6Dy6R8Xi31eDp1+6hrshESXFxGctzA/ckl2RAjhIQFRvrHssvHpRohw2Zl8k9rMnxrrU1PJSXiBWE2yppyauLCxO8hmWAvu/awbVFUSfwrtdUcuok9E95+S/bxG6hewAAAAPVBmnxJ4Q8mUwIV//44QAkop2IAiY6GwyxyIVzp8IjXIz5lN49pDxgvAlCNaagO+Jungole96BTvX33M7J1ZOuSZ82zoai/z3w0gFCQyzEJJk4x94TpvxKFOyC3SCrtzOfJxiZ21KaU3EY5mk3jgf4eLBEXdlh6EFCQ8tcfvkZaI/oZzTRMjG2CO6RsXuP+7z3/UbaochOu1aQmEGY0ryx483bzZe4rOeb97CDJiMqCkXwFcJIRAEzwc0n3ICjcu5JZT5HCmsJditdZfYAf7LHEozG3w85ucJPqUEX3VLLyHkV2Kk9nQbYP/UOmZF2fzDNxDdwccQAAAUJBmp1J4Q8mUwIV//44QAlo7ZQALqNLbKpc78kvB/jy6YGX/v8LmKiRNIZmNY7B/YfHSLZVcyA925xEDbJKqHIrWRgpojKGx57rAGElDmdyFQdZbw3o5ejuNGmO7qKhVu3IStITCHj/GMW/6KHelthVvrzo/btszJUh94KHmxRtB4rSSgFXlFsVjlmCcHjveWfnvaGa1OtMxuL5hqNv3ML/4zDKqrv2U4jNjGxkDXzzE4i7XWdtXTG6c1mw8BPyeW7WXDfQc09Yf7UvhNg89P3S68Th6XwuinEB+ws/qKgeW04hemaNhMVnwnyeUbcCJA2b7x3VYLrimDURFQqF8aLz7IPPS7q90afpHV/68Yvryus9OKdkQRf1yNh8FxQ3AdAQxmFygfPeW5ZYv2SfzntX99ENgkrPLXcOn7xiq96vowalAAAA8EGavknhDyZTAhX//jhAHA5ewAbXve0dBgm7L+l+zi7oCWTyzYcWlQ3u6pjOyxO4gpX+AJDquQufDiOtviB0HiH53JLs9Zhs96juy65I/BZikUGKbGHEAWnbKZBfkisGf0R15jYejNdt+AgPnW4dYjE1SsF73+qIGrZrkLbSzGRRqaHYBUGX2izgRtg4jyuHNj2nd2hA0o8pmRFFD5LyiWQVIljO/uJGyc8TJw0ML8E4bazP3bcGF9MCNvz8mOAHehOrScb5ovt+18OLma/fHyiItAlD4aYONJ4zfRsII+C9M5ODysgBuGg8XfMmgQA3oAAAAQlBmsBJ4Q8mUwURPCv//jhAHG6kXIQ6o6Jx6tK7sWhmAD8VDPgl1mSvNJRJWcQefgsFS5RttVtZ77DNnATGwe7rBNPff8h4Hw0Oa/JJ3tfZJE9a1GmX6ei73lNo5j0gVK29MxaquYQwXejAnO/c4RpUE9SO5ojDoluV0Moc+CF9jLTC9kED/DZiRh68MjDaTuMJhHjKhcpJQrgf66inV1AuB/nHo0oDcRsMkv/DCXxeX8OsF9RDwPplO/f/rm3MCIGBXPBkWeu2pFck4I9rFtOAzj1/qvv10fFqV6Or4fBXURjWOZTQACzpSOy0cuBaQsIWCj74oITtzA3YMS5xC7IBFz39Lmlh2AHzAAAA1wGe/2pH/wNb9kaX/sALyoRRJA33tsW9xHEgSUSECjdiljgIaZ1nlegwKd5L2Fr35GJHvDm5OseUyNCEQHcf/BZCGZ8on7uD2P3gCkPJ79eIBD38h++m5O6iiEzcs3H2H1XORv3pBNcWFNozW+D/RoWhEryY/GP4y5C0ZJ2OhkgM0adDw60Xk0Z65zxGm4b+qMYTke/PZyKS2zuffBrAQmf1ONQoGyToJns+MXvj2u/fs+dLa56ek2Z/JWaX47zAsbREUt/xvnrnepDWyqj90MtuKQp9KKGBAAAA8EGa4UnhDyZTAhX//jhAA42quGnP8uAEsk09oRR6KmBvRohJdmsGJuQPd/jkgaChVmKt+AjQMI27+4DtTcD/jjbc4yIKzio26WioszgG2OK+x/BH/9y+QCOCdP90mAW1P1ls4KOIg06HNGDtiJoDZvQVO7j8qSxpWcPP28BPoDBsqzkmDi0bJhIDlf7IEqb1AzwCyeVeHvGpi1vBcHpnpnzeFXcciUWRgFenDyl3TTIhxq+7pYCupS0+pSrl5wITG2Jt0AIPsyoW9e6ZaJnk6F9v693FED70A5JaHUc8BBcSbvUTRnKXIM6MncQvcAB0wAAAAOlBmwJJ4Q8mUwIV//44QAmoiMIAafCsyAPviA9xS//GiXf+iKMJEqJCHntlMmAoqryl+wJibo80W7WBzkCtjJjjByQmjDpMazuUYsUeZFBFSMkrWZTcat44wvvkVlGp6NKGGk27ta4vt6B8B+daLQnGhw6eVjsBwq3HMMEOFPmTIIdAimwh9v77d3VlrZO+MO8VsZdAHT5Bd7/XmaTesywY4kIi4eIXtvH0olFKMNCuCQUumvbZ8/tlsk5zjOYmZYBvRmSKSIgOG7BSR2ga1ikq+SYLv5s128gP9rjjruCkRGHajxTVOwA/wQAAAORBmyNJ4Q8mUwIV//44QAm3wOQnSvBWEIAsPlT5XFmd/S3opqSceM766Fh4/ELbr/CXVZiLoXMgAu4lp+fyyyYvWZDDFyjlYEWxJsVdNvSOoEH2CXRVj6MokT4fHNQ6OgA/yLSVLRSqNrV1nR7W4zM10Rh/Rtssk+GQqhwrnd4ujJLEWONfVDVc34LzcYhbjM4aaxQ2Vxbc8x0dFJDECiMUb1ljOWxmA++o4wyUWPNZCSHmtcooEkYCq2qBQVHJfVBoTptb66JdpdNTmCyW8pxFpzfhmeCi0Rzq0gf+cH+06Vt1QTcAAAD9QZtFSeEPJlMFETwr//44QAFI9rbt055C2nwfjm2XQAIMygVpN202TrksIFpT28TJNXsrWeR+Jjfg6TnTCvXfyATGAJHitPo3xQPU5hC9w/LYvAuRxRrx363xzUjnSXP21Q/v5sOMk7n9PmSC9xSFc4fQkB9uUB+LvB91PPwmrBi5ifNORyYfl3KxIUHkP8OQW1PPLdI+IF+8AjWaFmNwW9vRIF6YB/9B6xx1da017n/aZCOuQElmzPfOo/cNxqmu9fF5U2FfW1ipbY+qPLW5BRk/aEvxI/WTNjzRfC54YPyCh3ORsbwhFpoJsCiG4ryu1UjIAInxwR6jGaACNwAAAIcBn2RqR/8AK1+AAAM+fH3nZulXkoZURZTgv4pRvShMsMD9a9n4VTuYbSFnkbDA0fNYdb/AAVtpsrbTUNtJv04jDTnxpsWpS0f4rs6EDUK+Y0RdaiSDONpszJjhgu0sICQRu29hWn3AV55dXGq59H7T0Et4nC/uTvhEQrm5/7lMt7Byaswws4EAAAC5QZtmSeEPJlMCFf/+OEAABh2gYAA42U4vZHMHYjKXqe5cwHzj6167mmn/Uaff7/1MIwxAotnQlOB+Z09J/+MonbKjOCiyixTdund1rRkuwcR2wnTyaupu6v/QlmrXjyIt56o7Oyouxt2lYBmGwW7etMC6f1tFgCrk1M36Br5BRq+A+USVm8YD9pJAP6qAxemrPoAtRyZMYrYPmP+vPg41EA2zL2hFWRkjza/RlcHk8NVX51vSl+9+CPkAAADRQZuHSeEPJlMCFf/+OEAABk9VcGk6LAB/PNxys9MCLbSqdvV7uJ8rIMRSnS2769H6V79jgbjAsQwnopWCJazNBGuHBX3heBal3Jmk5bbhdTgGTQXjPJxWbgNCYE3PTiKCb9f47T9KsEbp7ECVETbIHs9UBXovgtHluU0/mUDjpsd6c0rkkzEWT5PcLEj4J9IAzW/8QGHJNyrKDY41YwPorIR5OzIXIvFX69AenU2dXP/GlpUgKXYzcyAPvh3bOKirj2Dxn4HUI//vB1DvvXHQJuEAAADAQZuoSeEPJlMCFf/+OEAAEG4l4JDNeAEtWlukNVeT6dz9fZrhRH77jH+T/lmn5Xha7DLQHaAS3aeergvqQLjnZGiIFqQ92nGWCWNdXXrcZn+1SgU1cKOp70TVXDj/dOJ3zq4C6DIa9F77ra5GZmqa0LJ5Ojf905og8SMMjn2yEP+ydL7I/cbh5sydOSLPOGXlhg60qigREYgEeB6IFhScdEeTOXIu3+uviNWAQzkv1qNEL52W3ol59U3L9+42AGfAAAAAx0GbyUnhDyZTAhX//jhAABDRfGwBzDSh7ZHzxyPd65y+BvxH9K3WVj7pJiFlyB/wZunczjy81FmzHm1rEx5EXXk+vwNn9GNAwhwe2aIV/wo3Xq8I1e+KYpaR+ujndjPaezCiaqOKGSVZr+72+6zPZnPZjigx57My/ulhUX6xp1u8CJZbi2DZnuvucWT2fkfKBBjNbouqhWMOQCZVBAbEB11r56Xu0S8dTZDIY3aPsW3/ZTIAaiMjkp+X0Z1HVMshaJmywJjQAyoAAADMQZvqSeEPJlMCFf/+OEAALVZQIAaqJ2rBUQqQbORZvyfvTvsfeblsRo6KKfcHnPgoQ7/riz0rtevEEdTwTujTPjlK5n6ZmqrRDF/IiCZ41ttWB2lQ6UZ0YDi7FY7XPtIfvMfTd9a3Pv9I2N+Jl9hA0T4giip5Um0TztluHnWuQP2fJXmlOkTFM6yDO/QJf53CHE2CxCFUgel8VUEssJRP1794Sl0jrHoF+v5GYJ69zwOBjfHkGhVAEpDsAIYp5ZJ+orc4/AQLepdYWUjBAAAAskGaC0nhDyZTAhX//jhAAC2fDgIPx0AOK28VW7F1uwn7edXvFtGQkT51DdjlOYiJq2iWVZ8Ss0Ml+2/AEa2fPIn1QTT1Ue7LJny3wi1y1ZBvu/aW8R6jXofVpgQE73lM9laxVf2wXUW+w3ZnEJ0wZHmRDK27+2aSZDfoDj6vqQotgFbe9x6TNxshV7PAWa37vsAddAviANkh+qXXTLCJM7N18w1wGhsmFac+HFZacYskSMAAAAEHQZosSeEPJlMCFf/+OEAALVcDAAG3TnoOoSAXjZ1M7hiGk+NDF9HExrXThY6Cr/fEbIOfqMnp19I1VgYSFdG+d4PTAHP/nM7McXeApeOw8vnklXcVDBIDgJ3XBDfSl+Y08DgpLMjst9WZzITY2kTHn2ocpj6dm1RmslLm0s2kU2Foo5vD4EEaz0d7dVXBMqF8jf4wklq2bnQ2B84vW9LixH9SIl0fZBKtSnxlPG4zWTg5Ic9ktXQIXi32CdGo6UQwq+eK6pvl0ovmHdTdZkG7eH5EVoo2kYNy3fdJnofTV14LmaGR5GQ7AFUD6zAmvxlqF2bNn6M+OCo7UHUe9ahhAevKJZVwz4AAAADcQZpNSeEPJlMCFf/+OEAALV3OEdq8ALWO4qtfG+BpinPvCfC+LIPJnhsXf99KCEAQ5lj/0wyPUrYp/e+oQlP2imGy1KPHDaVT+EcbOVtIB9YQzu68xQ2m7+krnBXNWeodYzrx5rLhW0Ig1gTbn6wSCFEtNMs4rquyrVVEa/k62g8s2gvwvABeCrV3rKRmK18Ulr2n86A8eJEP/3GWbWRqgaii591fKVyURriC5USObb579IEp8bL3anpdefP0AYVD3vm/z/mA034azRC12SBuiU+b5DVTqdkLB2AHrQAAAQhBmm5J4Q8mUwIV//44QAAud4PAAs9LVBO8OuzEKv7yfX/NpyoipaMHXPJLv6ySjix83Ol3/OXyX4vdPkBYkpu8FqrD/8qw36c14YSeRDQra5mSBIXeYQSw3KUHzeHc3fpa2Alpgg5RHd9DE3jJxlc8SUBrG6J3zOf3DIcq9qUIesAwoJZYD6Z0BjwjRqXqRyOQ7gvMDSP+WAi4Nx/SLcCx5sIOZEkT7M2cfTqTXyUX0Q5YHrkg7IxrM2etKExxwHS+hDSUcv3n7gYjSu6W3znGM4C+vlT5vhErmrd+rqSwbmT/lXNqgQ4qmj7NNTPjQ4r/krB2k9YtCYxKo7RYZzrauMfRJ8Q0MWEAAAEKQZqPSeEPJlMCFf/+OEAALr8OBRF+DwAOPQxd4cwcdSTNMU5vLVcsK2GYv+brctjPW2uCRSvKzqzawsYLuIik2XZvEBswAnE6wWKQcZDw+9NbjLXI9AOwH+H+1zZTL3n6J4YrzT58CZ3O+Kin3KxBme8/cjZBbiCMg2GOR2H4lm7xm1RwXvBvnE6eSXm144pdJ8izAiC+ZeY/0dgIwgtAEaGej+xVmansF6cGuECbqiUo0imoBhOBVy3cUpIkkOpdyGkIT9ZC9/mdIdZZD1v29yjEtpKag77EKK10Ng7SR8oNH0s7mbL6By2GfEtt8KLh1cs4pzZZFReZXxXqQB7Se7Vc75dM9Ehgq4EAAADxQZqwSeEPJlMCFf/+OEAAEO+CHE7Bx08R6qoAaEKZrXeGHEtjwoxnNWOS2XhiK3mdQ6bf4csW6sZebO2WEkc6Y26ky8f/6tyLURSAVQcCoRoWtnHYHRps7UfHNgzqWK2OCO7m9iND6o7SJ63pKWBAth4XFAzhNvwgideS2tib/ygvA+WRHyj2BYGLW5Muz8GWvn0JI5LMEgIFJAJnDvP0evpGn/uGYV3wyLqMLwWKofZXLxfz4VYLZTvQCb5oEprnyNndyN0bBgoj0BONFzrUo5/z9BYHDczA/nCBHnQ45VuAM/fIojw3ikcvdjVAjwDAgAAAAOtBmtFJ4Q8mUwIV//44QAACXfBERWHVUwm4QzSAEKeb6PLxV6vCiFctpLKVNlS/liAV83X9nv35H6s9vlGCwrrRsPKf2L8OdOEe0UXtN93h7sgQyDal63CIys9SwAyvQhWspy8lhNESxtqLVQYa8MolcTpsQYflqQWhXaZ90LFoCjhULUwsf0qT2oOLe2tMvYnz8WIB8u353aPHOdeCKDAxGSECQ/dMUbsToX0PC9Ks2ZL+B2lj+VpEaadooCy3QW8ME5841ZkX+igKAzumlkpTcrFs8X/edFAuoI9j0r+wfATlErl4ZG1KEcIcAAAA2kGa8knhDyZTAhf//oywAAAHoD8tgBB+2XOoRLqG5oGI2G/DIte+GWWeEjVZDyphKyQknovgcaTlQyM4k4e+5d03sQm3i9W6aZ/GHIKeU/B1Qshh6zJXdy8YSqqALb7oPzSvSWxX7Q+7x2TCeTyLHqXb3pbHHIzKY6DGsbh3orUxAAyyRpllxdYqzkGcuVocPyOgZbcrxVMwreBTetxdvW48wjHCbbCelXvUekF9Gln407ms7HvrQRn55DoJ5eE0OVZ4LzNPaX7DUojtx/+MuS5r/Z1s3Ny/UBsxAAABbkGbFknhDyZTAhX//jhAAAAdz1Iu+e6GMxNVGmSixw/PsYFYgA/0t3w3CpHD7eH1tXAGO7P/TolNr/3VWv3u0oahCCn5X2Nq/qQSrxnCotpbPPDpbOATNdpqZRmQSFBgAr1qhL8Nef+T+6YjNheXNvyu4GsPGbSYQ3ow3fQEKgWjDTMy9fH5cN6BAsuA5mHhDV3Yspew3J+letv2ojmqZL7Cn5Em13d4YuYcV2sUz+fdyFgWb+7v9KOw5JQr8QxytqCRsKCZQ6KU7ndhTOaq0UUvuxJwZ4N4ufsU2xkFJD5i8qv6y0TKreZKb0/KeaJfmr/sMuf10csuG5HFeNMF24eo9o0au8SJPlx9LUZTviyJ5IJDZIK+/FI0uV6FmkC5NWTD6VebUSv0OOYJVBcBQ50F01WV04oo1pCqbmgxSPpGRMy/kiAWZDBHY9x+zgO7o7RUmQHqxRks86D6WqIGkdxFctPKC9RoCQPosF5BlQAAAPJBnzRFETwj/wBMlFQVEVp52OCY+gA4wAWTBJAJWPEXBPAV1uTitAVpm2B04qSImQ/H4WLvYe2G+9BN5TDiIH43a77qOPHDYhu3r5DzarVVUzKJZUj5oOFOs5SJn2jsR+dR8pr8YUpalvBDsFisqozgRcHT9sHjSQ8cddBjROOhwzShoQCPoDDbo7UfKUKg3dR6cG3tv9Wm9pNOcaTBamTjCAsR4H0i7cHlhEu89iOY9D4zn4JOnMNy8KiLSd6dIqWFJLk3YZRMBCMoPUMXrm2kA65E+maPZBZoZMis194QWvtcqAOgyJjg5YDIgdRuevTFwAAAAMQBn1N0R/8AeWKPY0GTysqAHEsSXHtT3nSe1aXrreCtyJ0XCnWd7nE2uQJPsoLrBheRpyIxlrcO5b0TQusQHNKzjoHSJXsCYfmQ5eM1rGPuaHn9vYF3NUFFPNbvhK5nRQolOVE/ak0abhN8uR9n7ZjdhSqXhEMry4Mr628K9O1gwoRro1lJsJjVVk55qJeGTO9g9vn7a4htCFEDfCxdyYnZhdTQcJWc4z4lnN1cggAoeofnL+tgbCi0Z+DlV7TkhpRO6ALvAAAAvgGfVWpH/wB5n/im7rtAC/zIabsMfgb8+z0jCYLhAAnKBl6V9RANQ98mRNX4D9lVN5Zer1h1oWEczH1P/OMaiV5f+7Z6sShMzMug7BaovxxSI7HhfApll/NHu6eQ/wvNP8MK3miaRaMGI7wMz7uvSjCOPZfef7471Et/GSa3ohNHTNAVo1ANv1dN+pdt5UG6AsvqYOT0drhQM4nhk87vxzXXR8Wu45fRZDxaGOw9D/2jgC3MUfp3X4W1fFIIxWgAAAFBQZtaSahBaJlMCEf//eEAAAMAASb3VXu63/z2oApsCjWmlj+CuFv6+mfkQoJwLjln6mdGn/ms7dOvnsxkc/hVp+pmkzSVhJEC4tgH8GiFumc55qvC6fnwX2iHL+7xDpeQhgWPUzXsmGuEObobdjtyohUq8d5/SNOZ2HTONDxZsjeuwXuESxXNJSl2KJyDN7+wlu9hUM4HAYZnu2kMNbs6kmLA2ldNqBwzHgZZ8a2Vxt7RRbHOMGaI17iEoXqb6bvgsdkT1gAB7TammSnaaOOKsWhTI4OnjnSq8RMtvfghIaCGLWtmxbtcpvSVoXmwY3532uW9K1B0URNqNpxaM7RUrYw5CqSI+z9Mzo6wAiV/SnXm9FJGU03XfIsMVCdzX5HiXBENlv3/fvxSYr49p6DN8RiQXsDLtnQYdlN57cbE4lOnAAAAsUGfeEURLCP/AE2KfkAXUSengYcr063NS/5Kod/V7Wtb66BP/rPQATfkLum3I8bdHl6q6y0q4KnSAiQ7BwV20NsADOg3RQ3lks5KTz+i7na1LjZ+UOC5e2z+s9LNu6RbsdFnLEnd862SJt0OB1dNXb/1JIxXHOKbo6qASW3ayzyc26D4mVKH7R8YePBuTQ2c/sSzA5FFMiOUMQ9XOZJmEh8FeXblU2FtbdJ5CUqgUYn4EQAAADMBn5d0R/8AeWKPYHJUckh+LmnWt8+TvQgEqJ949++l2kN5DjJ2XkxPLhSFXP1tz2R4XJwAAACmAZ+Zakf/AHmf+KBdMHr3fuhR1N/iAHHG4yy6Glj99qYo/dpIBca+IrYs6cQl2NyPr1GEK7lD40iQkUy9Uf0kzqtmnKhBTNzB0+DLuRo4OhPpB3bym8VHD74Z+PfzdzG7Qqgs2HO9I4jsrdIdOvysNHFzAFIHj5DZ0l6ywfzKR6z6IppuN9bGBdUO41u/pP/bcFuQG2cUTiDySxRxfMl7X/acuLkQIQAAANxBm5tJqEFsmUwI//yEAAADAAPl6KSrZRojttlQAuGJSTHYCFaxIGq5DuZIGtQOT4Jo0PanZVBxe0Z5kAnAWbrIX6Cb6516D8UGTt+N7dFsPKAO42wCtk69zMUGWEVCui9BKlgqlQr87SqhA9kvhT120OobS1NZFajb4amxk3/l7LvlhCi1PfpHi5iFNjP7Y1Iy6Lmw0LiiHwbk4BEPxZwWFWCwxgr0f7CfEBaCJLZgiyGPPQutlj3AOPyUQ4t7clb3gQogKs8O1VyE1A3vT0dfta2zH6RfVjIaHtDtAAAIQm1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAmwAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAdtdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAmwAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAJYAAABkAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAJsAAAAgAAAQAAAAAG5W1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAHwAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAABpBtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAZQc3RibAAAALBzdHNkAAAAAAAAAAEAAACgYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAJYAZAASAAAAEgAAAAAAAAAARRMYXZjNjEuMy4xMDAgbGlieDI2NAAAAAAAAAAAAAAAABj//wAAADZhdmNDAWQAH//hABlnZAAfrNlAmDPl4QAAAwABAAADAGQPGDGWAQAGaOvjyyLA/fj4AAAAABRidHJ0AAAAAAABKKwAASisAAAAGHN0dHMAAAAAAAAAAQAAAHwAAAEAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAM4Y3R0cwAAAAAAAABlAAAAAQAAAgAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAMAAAIAAAAAAQAAAwAAAAABAAABAAAAAAEAAAIAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAAEAAACAAAAAAEAAAMAAAAAAQAAAQAAAAADAAACAAAAAAEAAAMAAAAAAQAAAQAAAAANAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAfAAAAAEAAAIEc3RzegAAAAAAAAAAAAAAfAAACS0AAAE2AAAAUQAAAEMAAABrAAAArAAAAHIAAABCAAAAWAAAAKAAAABjAAAAVwAAAGIAAACPAAAAewAAAGYAAACYAAAAeQAAAGkAAAB0AAAAgwAAAFgAAABHAAAAUgAAAFsAAABQAAAARwAAAGEAAACmAAAAZwAAAEgAAABkAAAAfQAAAE8AAABGAAAAYQAAAHMAAABbAAAARAAAAEUAAACiAAAATwAAAEcAAABPAAAAzAAAAGEAAABTAAAAUwAAAOQAAABfAAAASgAAAE8AAADrAAAAawAAAGUAAAFhAAAAvgAAAF8AAACWAAABMQAAAJQAAAE/AAAAoQAAAK8AAAFVAAAAtwAAAKsAAACbAAABFgAAALEAAACjAAAArgAAAOEAAACqAAAAmQAAAPIAAACWAAAA+wAAAJIAAAEGAAAAqQAAAOsAAAEHAAABAQAAAQUAAADSAAABAAAAAO4AAACWAAABJAAAAMYAAAEMAAAA+QAAAUYAAAD0AAABDQAAANsAAAD0AAAA7QAAAOgAAAEBAAAAiwAAAL0AAADVAAAAxAAAAMsAAADQAAAAtgAAAQsAAADgAAABDAAAAQ4AAAD1AAAA7wAAAN4AAAFyAAAA9gAAAMgAAADCAAABRQAAALUAAAA3AAAAqgAAAOAAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGF1ZHRhAAAAWW1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALGlsc3QAAAAkqXRvbwAAABxkYXRhAAAAAQAAAABMYXZmNjEuMS4xMDA=\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "def random_policy(obs, action_space):\n",
        "    return action_space.sample()\n",
        "\n",
        "def record_and_display(policy_fn: Callable, env_id: str = ENV_ID, seed: int = SEED,\n",
        "                       video_dir: str = VIDEO_DIR, max_steps: int = MAX_STEPS):\n",
        "    os.makedirs(video_dir, exist_ok=True)\n",
        "    env = make_env(env_id, seed=seed, render_mode=\"rgb_array\")\n",
        "    env = RecordVideo(env, video_dir, episode_trigger=lambda e: True, name_prefix=\"demo\")\n",
        "    total, _ = rollout_episode(env, policy_fn, max_steps=max_steps, capture_frames=False)\n",
        "    env.close()\n",
        "\n",
        "    mp4s = sorted(glob.glob(os.path.join(video_dir, \"*.mp4\")))\n",
        "    latest = mp4s[-1] if mp4s else None\n",
        "    print(f\"Episode return: {total:.2f}\")\n",
        "    if latest:\n",
        "        display(Video(latest, embed=True, html_attributes=\"controls loop autoplay\"))\n",
        "    else:\n",
        "        print(\"No video found. If on Colab, ensure imageio-ffmpeg is installed.\")\n",
        "    return total, latest\n",
        "\n",
        "# Example video of a random policy\n",
        "_ = record_and_display(random_policy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_action(agent, obs, action_space, epsilon: float = 0.0):\n",
        "  return agent.select_action(obs, action_space, epsilon)\n",
        "\n",
        "def to_tensor(obs: np.ndarray) -> torch.Tensor:\n",
        "    return torch.as_tensor(obs, dtype=torch.float32, device=DEVICE).unsqueeze(0)"
      ],
      "metadata": {
        "id": "R3r6LfpODV0K"
      },
      "id": "R3r6LfpODV0K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64086dc0"
      },
      "outputs": [],
      "source": [
        "def record_agent_video(agent: nn.Module, env_id: str = ENV_ID, seed: int = SEED,\n",
        "                       video_dir: str = VIDEO_DIR, max_steps: int = MAX_STEPS):\n",
        "    os.makedirs(video_dir, exist_ok=True)\n",
        "    env = make_env(env_id, seed=seed, render_mode=\"rgb_array\")\n",
        "    env = RecordVideo(env, video_dir, episode_trigger=lambda e: True, name_prefix=\"dqn\")\n",
        "    total = 0.0\n",
        "    obs, _ = env.reset(seed=seed)\n",
        "    for _ in range(max_steps):\n",
        "        obs = to_tensor(obs)\n",
        "        a = select_action(agent, obs, env.action_space, epsilon=0.0)\n",
        "        obs, r, term, trunc, _ = env.step(a)\n",
        "        total += float(r)\n",
        "        if term or trunc:\n",
        "            break\n",
        "    env.close()\n",
        "    mp4s = sorted(glob.glob(os.path.join(video_dir, \"*.mp4\")))\n",
        "    latest = mp4s[-1] if mp4s else None\n",
        "    print(f\"Agent video return: {total:.2f}\")\n",
        "    if latest:\n",
        "        display(Video(latest, embed=True, html_attributes=\"controls loop autoplay\"))\n",
        "    return total, latest\n"
      ],
      "id": "64086dc0"
    },
    {
      "cell_type": "markdown",
      "id": "0b72022d",
      "metadata": {
        "id": "0b72022d"
      },
      "source": [
        "\n",
        "## A) Tabular Q-Learning (with state discretization)\n",
        "\n",
        "LunarLander observations are continuous. We **bin** each dimension into a small number of buckets to get a discrete state key. Then we apply vanilla Q-learning:\n",
        "```\n",
        "Q[s,a] ← Q[s,a] + α (r + γ max_a' Q[s',a'] − Q[s,a])\n",
        "```\n",
        "Good for learning dynamics, but **DQN**s are preferred for function approximation and scalability.\n",
        "\n",
        "See what results you can get with the tabular Q-learning approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discretizer:\n",
        "    \"\"\"Uniformly discretize each observation dimension into `bins` buckets.\"\"\"\n",
        "    def __init__(self, low: np.ndarray, high: np.ndarray, bins: int = 8):\n",
        "        self.bins = bins\n",
        "        low = np.where(np.isfinite(low), low, -1.0)\n",
        "        high = np.where(np.isfinite(high), high, 1.0)\n",
        "        self.low = low\n",
        "        self.high = high\n",
        "\n",
        "    def encode(self, obs: np.ndarray) -> Tuple[int, ...]:\n",
        "        ratios = (obs - self.low) / (self.high - self.low + 1e-8)\n",
        "        ratios = np.clip(ratios, 0.0, 1.0)\n",
        "        idxs = (ratios * self.bins).astype(int)\n",
        "        idxs = np.clip(idxs, 0, self.bins - 1)\n",
        "        return tuple(int(i) for i in idxs)"
      ],
      "metadata": {
        "id": "BZ2vj7vdFuQ3"
      },
      "id": "BZ2vj7vdFuQ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "class LunarLanderAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: gym.Env,\n",
        "        learning_rate: float,\n",
        "        initial_epsilon: float,\n",
        "        epsilon_decay: float,\n",
        "        final_epsilon: float,\n",
        "        discount_factor: float = 0.95,\n",
        "    ):\n",
        "        \"\"\"Initialize a Q-Learning agent.\n",
        "\n",
        "        Args:\n",
        "            env: The training environment\n",
        "            learning_rate: How quickly to update Q-values (0-1)\n",
        "            initial_epsilon: Starting exploration rate (usually 1.0)\n",
        "            epsilon_decay: How much to reduce epsilon each episode\n",
        "            final_epsilon: Minimum exploration rate (usually 0.1)\n",
        "            discount_factor: How much to value future rewards (0-1)\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "\n",
        "        self.disc = Discretizer(env.observation_space.low, env.observation_space.high)\n",
        "\n",
        "        # Q-table: maps (state, action) to expected reward\n",
        "        # defaultdict automatically creates entries with zeros for new states\n",
        "        self.q_values = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "\n",
        "        self.lr = learning_rate\n",
        "        self.discount_factor = discount_factor  # How much we care about future rewards\n",
        "\n",
        "        # Exploration parameters\n",
        "        self.epsilon = initial_epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.final_epsilon = final_epsilon\n",
        "\n",
        "        # Track learning progress\n",
        "        self.training_error = []\n",
        "\n",
        "    def select_action(self, obs: tuple[int, int, bool], action_space = None, epsilon = None) -> int:\n",
        "        \"\"\"Choose an action using epsilon-greedy strategy.\n",
        "\n",
        "        Returns:\n",
        "            action: 0, 1, 2, or 3 (left, right, up, down)\n",
        "        \"\"\"\n",
        "        #TODO: implement the epsilon-greedy strategy\n",
        "\n",
        "        if epsilon is None:\n",
        "            current_epsilon = self.epsilon\n",
        "        else:\n",
        "            current_epsilon = epsilon\n",
        "\n",
        "        current_action_space = self.env.action_space if action_space is None else action_space\n",
        "\n",
        "        if RNG.random() < current_epsilon:\n",
        "            return current_action_space.sample()\n",
        "        else:\n",
        "            encoded_obs = self.disc.encode(obs)\n",
        "            return int(np.argmax(self.q_values[encoded_obs]))\n",
        "\n",
        "    def update(\n",
        "        self,\n",
        "        obs: tuple[int, int, bool],\n",
        "        action: int,\n",
        "        reward: float,\n",
        "        terminated: bool,\n",
        "        next_obs: tuple[int, int, bool],\n",
        "    ):\n",
        "        \"\"\"Update Q-value based on experience.\n",
        "\n",
        "        This is the heart of Q-learning: learn from (state, action, reward, next_state)\n",
        "        \"\"\"\n",
        "        obs = self.disc.encode(obs)\n",
        "        next_obs = self.disc.encode(next_obs)\n",
        "\n",
        "        # What should the Q-value be? (Bellman equation, defined as V(s) = max_a(R(s, a) + g*V(s')))\n",
        "        # a simplified version would be V(s) = R(s, a) + max(g*V(s')), which is basically saying that\n",
        "        # the expected value is equal the reward of the current state and action + the max/best q-value possible for the next state * some discount factor\n",
        "\n",
        "        # What's the best we could do from the next state?\n",
        "        # (Zero if episode terminated - no future rewards possible)\n",
        "        best_next_q = 0.0 if terminated else np.max(self.q_values[next_obs])\n",
        "\n",
        "        # Calculate target value using the Bellman equation\n",
        "        target = reward + self.discount_factor * best_next_q\n",
        "\n",
        "        # How wrong was our current estimate?\n",
        "        temporal_difference = target - self.q_values[obs][action]\n",
        "\n",
        "        # Update our estimate in the direction of the error\n",
        "        # Learning rate controls how big steps we take\n",
        "        self.q_values[obs][action] = (\n",
        "            self.q_values[obs][action] + self.lr * temporal_difference\n",
        "        )\n",
        "\n",
        "        # Track learning progress (useful for debugging)\n",
        "        self.training_error.append(temporal_difference)\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        \"\"\"Reduce exploration rate after each episode.\"\"\"\n",
        "        self.epsilon = max(self.final_epsilon, self.epsilon * self.epsilon_decay) # TODO: implement epsilon decaying\n"
      ],
      "metadata": {
        "id": "OVtt-3J3_Ja4"
      },
      "id": "OVtt-3J3_Ja4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_q_agent(agent, n_episodes):\n",
        "  for episode in tqdm(range(n_episodes)):\n",
        "      # Start a new landing\n",
        "      obs, info = env.reset()\n",
        "      done = False\n",
        "\n",
        "      while not done:\n",
        "          # Agent chooses action (initially random, gradually more intelligent)\n",
        "          action = agent.select_action(obs)\n",
        "\n",
        "          # Take action and observe result\n",
        "          next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "          # Learn from this experience\n",
        "          agent.update(obs, action, reward, terminated, next_obs)\n",
        "\n",
        "          # Move to next state\n",
        "          done = terminated or truncated\n",
        "          obs = next_obs\n",
        "\n",
        "      if episode % 1000 == 0:\n",
        "        print(\"Reward:\", reward)\n",
        "\n",
        "      # Reduce exploration rate (agent becomes less random over time)\n",
        "      agent.decay_epsilon()"
      ],
      "metadata": {
        "id": "IwGqRyiqGAvD"
      },
      "id": "IwGqRyiqGAvD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters\n",
        "learning_rate = 0.01        # @param How fast to learn (higher = faster but less stable)\n",
        "n_episodes = 50_000        # @param Number of landings to practice (may need to increase this)\n",
        "start_epsilon = 1.0         # @param Start with 100% random actions\n",
        "epsilon_decay = 0.997 # @param Reduce exploration over time\n",
        "min_epsilon = 0.1         # @param Always keep some exploration\n",
        "\n",
        "# Create environment and agent\n",
        "env = make_env(ENV_ID, SEED, render_mode=None)\n",
        "env = gym.wrappers.RecordEpisodeStatistics(env, buffer_length=n_episodes)\n",
        "\n",
        "q_agent = LunarLanderAgent(\n",
        "    env=env,\n",
        "    learning_rate=learning_rate,\n",
        "    initial_epsilon=start_epsilon,\n",
        "    epsilon_decay=epsilon_decay,\n",
        "    final_epsilon=min_epsilon,\n",
        ")"
      ],
      "metadata": {
        "id": "xKkakayh_ZxV"
      },
      "id": "xKkakayh_ZxV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_q_agent(q_agent, n_episodes)"
      ],
      "metadata": {
        "id": "Fle5Eww9_j3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf59fc4-11af-4b3d-d24e-2fb28531bca4"
      },
      "id": "Fle5Eww9_j3X",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 24/50000 [00:00<10:21, 80.39it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1003/50000 [00:34<40:14, 20.29it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 2010/50000 [01:27<29:46, 26.87it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 3008/50000 [02:29<40:00, 19.58it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 4005/50000 [03:30<37:13, 20.59it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 5008/50000 [04:23<40:39, 18.44it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 6008/50000 [05:23<41:26, 17.69it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 7001/50000 [06:27<1:06:17, 10.81it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: 2.2381732197154607\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 8005/50000 [07:30<47:56, 14.60it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 9008/50000 [08:36<44:06, 15.49it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 10009/50000 [09:40<38:22, 17.37it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 11007/50000 [10:35<25:37, 25.37it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 12005/50000 [11:37<40:50, 15.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 13004/50000 [12:40<30:37, 20.14it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 14008/50000 [13:40<23:01, 26.05it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 15011/50000 [14:41<23:15, 25.07it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 16005/50000 [15:44<41:51, 13.54it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: 0.5195802250001094\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 17007/50000 [16:41<36:27, 15.08it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 18003/50000 [17:48<38:35, 13.82it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 19005/50000 [18:55<47:24, 10.90it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -1.677065548293952\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 20006/50000 [19:56<28:12, 17.72it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 21005/50000 [21:01<22:19, 21.65it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 22007/50000 [21:57<19:15, 24.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 23005/50000 [22:54<27:51, 16.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -5.254029800977775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 24004/50000 [24:00<25:23, 17.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 25009/50000 [25:02<21:29, 19.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 26009/50000 [25:53<25:40, 15.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 27003/50000 [26:49<37:32, 10.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 28003/50000 [27:53<33:46, 10.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: 0.15619522850654846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 29004/50000 [28:57<31:16, 11.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 30010/50000 [29:51<14:09, 23.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 31007/50000 [30:55<25:45, 12.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -1.9751102299804189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 32006/50000 [32:00<22:10, 13.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 33006/50000 [33:02<22:27, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 34008/50000 [34:03<18:25, 14.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 35005/50000 [34:55<16:46, 14.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 36009/50000 [35:52<07:15, 32.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 37006/50000 [36:54<15:24, 14.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 38003/50000 [37:58<12:38, 15.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 39005/50000 [39:00<06:39, 27.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 40007/50000 [40:06<10:02, 16.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 41008/50000 [41:02<08:06, 18.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 42006/50000 [42:01<08:35, 15.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 43009/50000 [43:05<06:52, 16.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 44004/50000 [44:12<04:07, 24.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 45005/50000 [45:06<05:47, 14.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 46006/50000 [46:11<04:02, 16.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 47003/50000 [47:16<02:58, 16.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 48010/50000 [48:22<01:43, 19.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 49004/50000 [49:19<00:56, 17.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward: -0.013746548534778497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [50:14<00:00, 16.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize your tabular Q-learning lunar lander\n"
      ],
      "metadata": {
        "id": "iPU9mHalFa5C"
      },
      "id": "iPU9mHalFa5C"
    },
    {
      "cell_type": "code",
      "source": [
        "record_agent_video(q_agent)"
      ],
      "metadata": {
        "id": "kmBhbI_ZDz-I"
      },
      "id": "kmBhbI_ZDz-I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "71676201",
      "metadata": {
        "id": "71676201"
      },
      "source": [
        "\n",
        "## B) Double DQN (Deep Q-Network)\n",
        "\n",
        "We train a \"policy\" Q-network (`DQNModel`) with:\n",
        "- **Experience Replay** buffer\n",
        "- **Target Network** (periodically updated)\n",
        "  - this separate network is used to calculate target Q-values, which decouples action selection (done by the policy network) and action evaluation\n",
        "  - typically less prone to overestimating Q-values than standard single network DQN\n",
        "- **ε-greedy** exploration\n",
        "- **Huber loss** and **Adam** optimizer\n",
        "\n",
        "Complete any TODOs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "918938a7"
      },
      "outputs": [],
      "source": [
        "class DQNModel(nn.Module):\n",
        "    \"\"\"Q-network architecture.\n",
        "\n",
        "    For LunarLander:\n",
        "      - Input: observation vector shape [8]\n",
        "      - Output: Q-values for each action (shape [n_actions], 4)\n",
        "    \"\"\"\n",
        "    def __init__(self, obs_dim: int, n_actions: int, hidden: int = 128):\n",
        "        super().__init__()\n",
        "        # TODO: implement architecture\n",
        "        # hint: very simple MLP is all you need\n",
        "        self.dim = obs_dim\n",
        "        self.action = n_actions\n",
        "        self.hidden = hidden\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      #TODO: return the model output (the Q-value)\n",
        "      print(x)\n",
        "      return x\n",
        "\n",
        "    def select_action(self, obs: np.ndarray, action_space, epsilon: float = 0.0) -> int:\n",
        "      \"\"\"Map model outputs to a valid discrete action.\n",
        "\n",
        "      - With probability epsilon, choose a random action.\n",
        "      - Otherwise, choose argmax Q-value from the model.\n",
        "      \"\"\"\n",
        "      # TODO: return an action (int in {0,1,2,3})\n",
        "      # hint: similar to how you implemented epsilon-greedy in tabular q-learning, but how do you find the max q-value from the model?\n",
        "      # think about what the network represents or approximates\n",
        "      raise NotImplementedError(\"implement epsilon-greedy over model Q-values here.\")\n",
        "\n"
      ],
      "id": "918938a7"
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "Transition = namedtuple(\n",
        "    \"Transition\", [\"state\", \"action\", \"next_state\", \"reward\", \"done\"]\n",
        ")\n",
        "\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return (\n",
        "            random.sample(self.memory, batch_size)\n",
        "            if batch_size < len(self.memory)\n",
        "            else self.memory\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "SJXLKiGRUnLK"
      },
      "id": "SJXLKiGRUnLK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b0604ee",
      "metadata": {
        "id": "4b0604ee"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class DQNConfig:\n",
        "  num_episodes: int = 500 # @param\n",
        "  gamma: float = 0.99 # @param\n",
        "  learning_rate: float = 1e-4 # @param\n",
        "  tau: float = 0.005 # @param\n",
        "  batch_size: int = 128 # @param\n",
        "  epsilon: float = 1.0 # @param\n",
        "  epsilon_decay: float = 0.995 # @param\n",
        "  epsilon_min: float = 0.01 # @param\n",
        "  eval_interval: int = 100 # @param\n",
        "  eval_episodes: int = 5 # @param\n",
        "  max_grad_norm: float = 10.0 # @param\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e3dd6b3",
      "metadata": {
        "id": "0e3dd6b3"
      },
      "outputs": [],
      "source": [
        "# def linear_epsilon(step: int, start: float, end: float, decay_steps: int) -> float:\n",
        "#     if step >= decay_steps:\n",
        "#         return end\n",
        "#     return start + (end - start) * (step / float(decay_steps))\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(model: nn.Module, episodes: int = 5, env_id: str = ENV_ID, seed: int = SEED):\n",
        "    scores = []\n",
        "    for ep in range(episodes):\n",
        "        env = make_env(env_id, seed=seed + ep, render_mode=None)\n",
        "        total = 0.0\n",
        "        obs, _ = env.reset(seed=seed + ep)\n",
        "        for _ in range(MAX_STEPS):\n",
        "            obs = to_tensor(obs)\n",
        "            a = select_action(model, obs, env.action_space, epsilon=0.0)\n",
        "            obs, r, term, trunc, _ = env.step(a)\n",
        "            total += float(r)\n",
        "            if term or trunc:\n",
        "                break\n",
        "        env.close()\n",
        "        scores.append(total)\n",
        "    mean_ret = float(np.mean(scores))\n",
        "    print(f\"Eval over {episodes} episodes — mean return: {mean_ret:.2f}\")\n",
        "    return mean_ret\n",
        "\n",
        "def dqn_train(cfg: DQNConfig):\n",
        "    # Initialize the environment\n",
        "    env = gym.make(ENV_ID, render_mode=\"human\")\n",
        "\n",
        "    n_observations = env.observation_space.shape[0]\n",
        "    n_actions = env.action_space.n\n",
        "\n",
        "    policy_net = DQNModel(n_observations, n_actions).to(DEVICE)\n",
        "    target_net = DQNModel(n_observations, n_actions).to(DEVICE)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    replay_memory = ReplayMemory(10_000)\n",
        "\n",
        "    optimizer = optim.AdamW(policy_net.parameters(), lr=cfg.learning_rate)\n",
        "    # smooth l1 loss is implementation of Huber loss (MSE for small errors, L1 for larger errors)\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "\n",
        "    epsilon = cfg.epsilon\n",
        "\n",
        "    best_reward = float(\"-inf\")\n",
        "\n",
        "    for episode in tqdm(range(cfg.num_episodes)):\n",
        "      state, _ = env.reset(seed=SEED)\n",
        "      state = to_tensor(state)\n",
        "      tracker = RewardTracker()\n",
        "      total_reward = 0.0\n",
        "\n",
        "      while True:\n",
        "        action = select_action(policy_net, state, env.action_space, epsilon)\n",
        "        next_state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        reward = torch.tensor([reward], device=DEVICE)\n",
        "        next_state = to_tensor(next_state)\n",
        "        replay_memory.push(state, torch.tensor([[action]], device=DEVICE), next_state, reward, done)\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += 0 #TODO: fix the total_reward update line\n",
        "\n",
        "        if len(replay_memory) >= cfg.batch_size:\n",
        "            transitions = replay_memory.sample(cfg.batch_size)\n",
        "            states, actions, next_states, rewards, dones = zip(*transitions)\n",
        "\n",
        "            states_batch = torch.cat(states)\n",
        "            next_states_batch = torch.cat(next_states)\n",
        "            actions_batch = torch.cat(actions)\n",
        "            rewards = torch.tensor(rewards, device=DEVICE)\n",
        "            dones = torch.tensor(dones, device=DEVICE)\n",
        "\n",
        "            # target network calculates target q-values (action evaluation)\n",
        "            q_target = (\n",
        "                cfg.gamma * target_net(next_states_batch).detach().max(-1)[0] * ~dones\n",
        "                + rewards\n",
        "            )\n",
        "\n",
        "            #policy network determines action selection\n",
        "            q_policy = policy_net(states_batch).gather(1, actions_batch)\n",
        "\n",
        "            # Calculate the Huber loss (remember that the Huber loss behaves like MSE for errors < q_target and L1 for errors > q_target)\n",
        "            loss = None  #TODO: use the criterion defined above\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # In-place gradient clipping to stabilize training\n",
        "            # TODO: use gradient norm clipping on the policy network; see torch.nn.utils.clip_grad_norm_()\n",
        "            # hint: there is a config member named `max_grad_norm`\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "        # Update target network (target network is updated less frequently, and it is updated by copying weights from the policy network)\n",
        "        for target_param, main_param in zip(target_net.parameters(), policy_net.parameters()):\n",
        "            target_param.data.copy_(cfg.tau * main_param.data + (1 - cfg.tau) * target_param.data)\n",
        "\n",
        "        if done:\n",
        "            tracker.update(total_reward)\n",
        "            if total_reward > best_reward:\n",
        "                best_reward = total_reward\n",
        "                torch.save(policy_net.state_dict(), \"best_policy.pth\")\n",
        "            if episode % 25 == 0:\n",
        "                print(f\"Episode {episode}, Reward: {total_reward}, Epsilon: {epsilon:.3f}\")\n",
        "            if episode % cfg.eval_interval == 0:\n",
        "                evaluate_model(policy_net, episodes=cfg.eval_episodes)\n",
        "            break\n",
        "\n",
        "      epsilon = epsilon # TODO: decay the epsilon\n",
        "\n",
        "    env.close()\n",
        "    return policy_net, target_net, replay_memory, tracker\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# default config should work well, but you are encouraged to try different hyperparams;\n",
        "# e.g., increasing the number of episodes or experimenting with decay rate\n",
        "cfg = DQNConfig()"
      ],
      "metadata": {
        "id": "n_1_BPZwm41c"
      },
      "id": "n_1_BPZwm41c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51f01ea4",
      "metadata": {
        "id": "51f01ea4"
      },
      "outputs": [],
      "source": [
        "# will raise NotImplementedError until you implement the TODOs in DQNModel\n",
        "policy_net, target_net, rb, tracker = dqn_train(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_policy_net_state = torch.load(\"best_policy.pth\")\n",
        "best_policy_net = DQNModel(8, 4).to(DEVICE)\n",
        "best_policy_net.load_state_dict(best_policy_net_state)"
      ],
      "metadata": {
        "id": "9ezRM_XfCraO"
      },
      "id": "9ezRM_XfCraO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c20e8f76",
      "metadata": {
        "id": "c20e8f76"
      },
      "source": [
        "### Visualize your lunar lander\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f283f45",
      "metadata": {
        "id": "3f283f45"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print(f\"Final moving average: {tr.moving_avg:.2f}\")\n",
        "record_agent_video(best_policy_net)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}